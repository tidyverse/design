[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tidy design principles",
    "section": "",
    "text": "Welcome\nThe goal of this book is to help you write better R code. It has four main components:\n\nIdentifying design challenges that often lead to suboptimal outcomes.\nIntroducing useful patterns that help solve common problems.\nDefining key principles that help you balance conflicting patterns.\nDiscussing case studies that help you see how all the pieces fit together with real code.\n\nWhile I’ve called these principles “tidy” and they’re used extensively by the tidyverse team to promote consistency across our packages, they’re not exclusive to the tidyverse. Think tidy in the sense of tidy data (broadly useful regardless of what tool you’re using) not tidyverse (a collection of functions designed with a singular point of view in order to facilitate learning and use).\nThis book will be under heavy development for quite some time; currently we are loosely aiming for completion in 2025. You’ll find many chapters contain disjointed text that mostly serve as placeholders for the authors, and I do not recommend attempting to systematically read the book at this time. If you’d like to follow along with my journey writing this book, and learn which chapters are ready to read, please sign up for my tid design substack mailing list."
  },
  {
    "objectID": "unifying.html#human-centered",
    "href": "unifying.html#human-centered",
    "title": "1  Unifying principles",
    "section": "1.1 Human centered",
    "text": "1.1 Human centered\n\nPrograms must be written for people to read, and only incidentally for machines to execute.\n— Hal Abelson\n\nProgramming is a task performed by humans. To create effective programming tools we must explicitly recognise and acknowledge the role played by cognitive psychology. This is particularly important for R, because it’s a language that’s used primarily by non-programmers, and we want to make it as easy as possible for first-time and end-user programmers to learn the tidyverse.\nA particularly useful tool from cognitive psychology is “cognitive load theory”1: we have a limited working memory, and anything we can do to reduce extraneous cognitive load helps the learner and user of the tidyverse. This motivates the next two principles:\n\nBy being consistent you only need to learn and internalise one expression of an idea, and then you can apply that many times.\nBy being composable you can break down complex problems into bite sized pieces that you can easily hold in your head.\n\nIdea of “chunking” is important. Some setup cost to learn a new chunk, but once you’ve internalised it, it only takes up one spot in your working memory. In some sense the goal of the tidyverse is to discover the minimal set of chunks needed to do data science and have some sense of the priority of the remainder.\nOther useful ideas come from design. One particularly powerful idea is that of “affordance”: the exterior of a tool should suggest how to use it. We want to avoid “Norman doors” where the exterior clues and cues point you in the wrong direction.\nThis principle is deeply connected to our beliefs about performance. Most importantly performance of code depends not only on how long it takes to run, but also how long it takes to write and read. Human brains are typically slower than computers, so this means we spend a lot of time thinking about how to create intuitve interfaces, focussing on writing and reading speed. Intuitive interfaces sometimes are at odds with running speed, because writing the fastest code for a problem often requires designing the interface for performance rather than usability. Generally, we optimise first for humans, then use profiling to discover bottlenecks that cause friction in data analysis. Once we have identified an important bottleneck, then performance becomes a priority and we rewrite the existing code. Generally, we’ll attempt to preserve the existing interface, only changing it when the performance implications are significant."
  },
  {
    "objectID": "unifying.html#consistent",
    "href": "unifying.html#consistent",
    "title": "1  Unifying principles",
    "section": "1.2 Consistent",
    "text": "1.2 Consistent\n\nA system should be built with a minimum set of unchangeable parts; those parts should be as general as possible; and all parts of the system should be held in a uniform framework.\n— Daniel H. H. Ingalls\n\nThe most important API principle of the tidyverse is to be consistent. We want to find the smallest possible set of key ideas and use them again and again. This is important because it makes the tidyverse easier to learn and remember.\n(Another framing of this principle is Less Volume, More Creativity, which comes from Mike McCarthy, the head coach of the Green Bay Packers, and popularised in Statistics Education by Randall Pruim)\nThis is related to one of my favourite saying from the Python community:\n\nThere should be one—and preferably only one—obvious way to do it.\n— Zen of Python\n\nThe tidyverse aspires to put this philosophy into practice. However, because the tidyverse is embedded within the larger R ecosystem, applying this principle never needs to be 100% comprehensive. If you can’t solve a problem from within the tidyverse, you can always step outside and do so with base R or another package. This also means that we don’t have to rush to cover every possible use case; we can take our time to develop the best new solutions.\nThe principle of consistency reveals itself in two primary ways: in function APIs and in data structures. The API of a function defines its external interface (independent of its internal implementation). Having consistent APIs means that each time you learn a function, learning the next function is a little easier; once you’ve mastered one package, mastering the next is easier.\nThere are two ways that we make functions consistent that are so important that they’re explicitly pull out as high-level principles below:\n\nFunctions should be composable: each individual function should tackle one well contained problem, and you solve complex real-world problems by composing many individual functions.\nOverall, the API should feel “functional”, which is a technical term for the programming paradigm favoured by the tidyverse\n\nBut consistency also applies to data structures: we want to ensure we use the same data structures again and again and again. Principally, we expect data to be stored in tidy data frames or tibbles. This means that tools for converting other formats can be centralised in one place, and that packages development is simplified by assuming that data is already in a standard format.\nValuing consistency is a trade-off, and we explicitly value it over performance. There are cases where a different data structure or a different interface might make a solution simpler to express or much faster. However, one-off solutions create a much higher cognitive load."
  },
  {
    "objectID": "unifying.html#composable",
    "href": "unifying.html#composable",
    "title": "1  Unifying principles",
    "section": "1.3 Composable",
    "text": "1.3 Composable\n\nNo matter how complex and polished the individual operations are, it is often the quality of the glue that most directly determines the power of the system.\n— Hal Abelson\n\nA powerful strategy for solving complex problems is to combine many simple pieces. Each piece should be easily understood in isolation, and have a standard way of combining with other pieces.\nWithin the tidyverse, we prefer to compose functions using a single tool: the pipe, %&gt;%. There are two notable exceptions to this principle: ggplot2 composes graphical elements with +, and httr composes requests primarily through .... These are not bad techniques in isolation, and they are well suited to the domains in which they are used, but the disadvantages of inconsistency outweigh any local advantages.\nFor smaller domains, this means carefully designing functions so that the inputs and outputs align (e.g. the output from stringr::str_locate() can easily be fed into str_sub()). For middling domains, this means drawing many feature matrices and ensuring that they are dense (e.g. consider the map family in purrr). For larger domains, this means carefully thinking about algebras and grammars, identifying the atoms of a problem and the ways in which they might be composed to solve bigger problems.\nWe decompose large problems into smaller, more tractable ones by creating and combining functions that transform data rather than by creating objects whose state changes over time.\nOther techniques that tend to facilitate composability:\n\nFunctions are data: this leads some of the most impactful techniques for functional programming, which allow you to reduce code duplication.\nImmutable objects. Enforces independence between components.\nPartition side-effects.\nType-stable."
  },
  {
    "objectID": "unifying.html#inclusive",
    "href": "unifying.html#inclusive",
    "title": "1  Unifying principles",
    "section": "1.4 Inclusive",
    "text": "1.4 Inclusive\nWe value not just the interface between the human and the computer, but also the interface between humans. We want the tidyverse to be a diverse, inclusive, and welcoming community.\n\nWe develop educational materials that are accessible to people with many different skill levels.\nWe prefer explicit codes of conduct.\nWe create safe and friendly communities. We believe that kindness should be a core value of communities.\nWe think about how we can help others who are not like us (they may be visually impaired or may not speak English).\n\nWe also appreciate the paradox of tolerance: the only people that we do not welcome are the intolerant."
  },
  {
    "objectID": "unifying.html#footnotes",
    "href": "unifying.html#footnotes",
    "title": "1  Unifying principles",
    "section": "",
    "text": "A good practical introduction is Cognitive load theory in practice (PDF).↩︎"
  },
  {
    "objectID": "names.html#coverage-in-tidyverse-style-guide",
    "href": "names.html#coverage-in-tidyverse-style-guide",
    "title": "\n2  Names attribute\n",
    "section": "\n2.1 Coverage in tidyverse style guide",
    "text": "2.1 Coverage in tidyverse style guide\nExisting name-related topics in http://style.tidyverse.org\n\nFile names\nObject names\nArgument names\nFunction names"
  },
  {
    "objectID": "names.html#the-names-attribute-of-an-object",
    "href": "names.html#the-names-attribute-of-an-object",
    "title": "\n2  Names attribute\n",
    "section": "\n2.2 The names attribute of an object",
    "text": "2.2 The names attribute of an object\nHere we address how to manage the names attribute of an object. Our initial thinking was motivated by how to handle the column or variable names of a tibble, but is evolving into a name-handling strategy for vectors, in general.\nThe name repair described below is exposed to users via the .name_repair argument of tibble::tibble(), tibble::as_tibble(), readxl::read_excel(), and, eventually other packages in the tidyverse. This work was initiated in the tibble package, but is migrating to the vctrs package. Name repair was first introduced in tibble v2.0.0 and this write-up is being rendered with tibble v3.2.1 and vctrs v0.6.3.\nThese are the kind of names we’re talking about:\n\n## variable names\nnames(iris)\n#&gt; [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"\n\nnames(ChickWeight)\n#&gt; [1] \"weight\" \"Time\"   \"Chick\"  \"Diet\"\n\n## names along a vector\nnames(euro)\n#&gt;  [1] \"ATS\" \"BEF\" \"DEM\" \"ESP\" \"FIM\" \"FRF\" \"IEP\" \"ITL\" \"LUF\" \"NLG\" \"PTE\""
  },
  {
    "objectID": "names.html#minimal-unique-universal",
    "href": "names.html#minimal-unique-universal",
    "title": "\n2  Names attribute\n",
    "section": "\n2.3 Minimal, unique, universal",
    "text": "2.3 Minimal, unique, universal\nWe identify three nested levels of naminess that are practically useful:\n\nMinimal: The names attribute is not NULL. The name of an unnamed element is \"\" (the empty string) and never NA.\nUnique: No element of names appears more than once. A couple specific names are also forbidden in unique names, such as \"\" (the empty string).\n\nAll columns can be accessed by name via df[[\"name\"]] and, more generally, by quoting with backticks: df$`name`, subset(df, select = `name`), and dplyr::select(df, `name`).\n\n\nUniversal: The names are unique and syntactic.\n\nNames work everywhere, without quoting: df$name and lm(name1 ~ name2, data = df) and dplyr::select(df, name) all work.\n\n\n\nBelow we give more details and describe implementation."
  },
  {
    "objectID": "names.html#minimal-names",
    "href": "names.html#minimal-names",
    "title": "\n2  Names attribute\n",
    "section": "\n2.4 Minimal names",
    "text": "2.4 Minimal names\nMinimal names exist. The names attribute is not NULL. The name of an unnamed element is \"\" (the empty string) and never NA.\nConsider an unnamed vector, i.e. it has names attribute of NULL.\n\nx &lt;- letters[1:3]\nnames(x)\n#&gt; NULL\n\nThis means that the names of x are sometimes a character vector the same length of x, and sometimes NULL. rlang papers of this problem by providing names2() which always returns a character vector:\n\nrlang::names2(x)\n#&gt; [1] \"\" \"\" \"\"\n\nAnd you can also use this to ensure a vector has minimal names:\n\nnames(x) &lt;- rlang::names2(x)\nnames(x)\n#&gt; [1] \"\" \"\" \"\"\n\nMinimal names appear to be a useful baseline requirement, if the names attribute of an object is going to be actively managed. Why? General name handling and repair can be implemented more simply if the baseline strategy guarantees that names(x) returns a character vector of the correct length with no NAs.\nThis is also a reasonable interpretation of base R’s intent for named vectors, based on the docs for names(), although base R’s implementation/enforcement of this is uneven. From ?names:\n\nThe name \"\" is special: it is used to indicate that there is no name associated with an element of a (atomic or generic) vector. Subscripting by \"\" will match nothing (not even elements which have no name).\nA name can be character NA, but such a name will never be matched and is likely to lead to confusion.\n\ntbl_df objects created by tibble::tibble() and tibble::as_tibble() have variable names that are minimal, at the very least."
  },
  {
    "objectID": "names.html#unique-names",
    "href": "names.html#unique-names",
    "title": "\n2  Names attribute\n",
    "section": "\n2.5 Unique names",
    "text": "2.5 Unique names\nUnique names meet the requirements for minimal and have no duplicates. In the tidyverse, we go further and repair a few specific names: \"\" (the empty string), ... (R’s ellipsis or “dots” construct), and ..j where j is a number. They are basically all treated like \"\", which is always repaired.\nExample of unique-ified names:\n\n## original unique-ified\n##       \"\"         ...1\n##        x        x...2\n##       \"\"         ...3\n##      ...         ...4\n##        y            y\n##        x        x...6\n\nThis augmented definition of unique has a specific motivation: it ensures that each element can be identified by name, at least when protected by backtick quotes. Literally, all of these work:\n\ndf[[\"name\"]]\ndf$`name`\nwith(df, `name`)\nsubset(df, select = `name`)\ndplyr::select(df, `name`)\n\nThis has practical significance for variable names inside a data frame, because so many workflows rely on indexing by name. Note that uniqueness refers implicitly to a vector of names.\nLet’s explore a few edge cases: A single dot followed by a number, .j, does not need repair.\n\ndf &lt;- tibble(`.1` = \"ok\")\ndf$`.1`\n#&gt; [1] \"ok\"\nsubset(df, select = `.1`)\n#&gt; # A tibble: 1 × 1\n#&gt;   `.1` \n#&gt;   &lt;chr&gt;\n#&gt; 1 ok\ndplyr::select(df, `.1`)\n#&gt; # A tibble: 1 × 1\n#&gt;   `.1` \n#&gt;   &lt;chr&gt;\n#&gt; 1 ok\n\nTwo dots followed by a number, ..j, does need repair. The same goes for three dots, ..., the ellipsis or “dots” construct. These can’t function as names, even if quoted with backticks, so they have to be repaired.\n\ndf &lt;- tibble(`..1` = \"not ok\")\n#&gt; Error in `tibble()`:\n#&gt; ! Column 1 must not have names of the form ... or ..j.\n#&gt; Use `.name_repair` to specify repair.\n#&gt; Caused by error in `repaired_names()`:\n#&gt; ! Names can't be of the form `...` or `..j`.\n#&gt; ✖ These names are invalid:\n#&gt;   * \"..1\" at location 1.\nwith(df, `..1`)\n#&gt; Error in eval(substitute(expr), data, enclos = parent.frame()): ..1 used in an incorrect context, no ... to look in\ndplyr::select(df, `..1`)\n#&gt; Error in dot_call(capture_dots, frame_env = frame_env, named = named, : '...' used in an incorrect context\n\ndf &lt;- tibble(`...` = \"not ok\")\n#&gt; Error in `tibble()`:\n#&gt; ! Column 1 must not have names of the form ... or ..j.\n#&gt; Use `.name_repair` to specify repair.\n#&gt; Caused by error in `repaired_names()`:\n#&gt; ! Names can't be of the form `...` or `..j`.\n#&gt; ✖ These names are invalid:\n#&gt;   * \"...\" at location 1.\nsubset(df, select = `...`)\n#&gt; Error in eval(expr, envir, enclos): '...' used in an incorrect context\ndplyr::select(df, `...`)\n#&gt; Error in eval(expr, envir, enclos): '...' used in an incorrect context\n\nBoth are repaired as if they were \"\".\n\n2.5.1 Making names unique\nThere are many ways to make names unique. We append a suffix of the form ...j to any name that is a duplicate or \"\" or ..., where j is the position. Why?\n\nAn absolute position j is more helpful than numbering within the elements that share a name. Context: troubleshooting data import with lots of columns and dysfunctional names.\nWe hypothesize that it’s better have a “level playing field” when repairing names, i.e. if foo appears twice, both instances get repaired, not just the second occurrence.\n\nThe unique level of naminess is regarded as normative for a tibble and a user must expressly request a tibble with names that violate this (but that is possible).\nBase R’s function for this is make.unique(). We revisit the example above, comparing the tidyverse strategy for making names unique vs. what make.unique() does.\n\n## Original Unique names     Result of\n##    names  (tidyverse) make.unique()\n##       \"\"         ...1            \"\"\n##        x        x...2             x\n##       \"\"         ...3            .1\n##      ...         ...4           ...\n##        y            y             y\n##        x        x...6           x.1\n\n\n2.5.2 Roundtrips\nWhen unique-ifying names, we assume that the input names have been repaired by the same strategy, i.e. that we are consuming dogfood. Therefore, pre-existing suffixes of the form ...j are stripped, prior to (re-)constructing the suffixes. If this interacts poorly with your names, you need to take control of name repair.\nExample of re-unique-ified names:\n\n##  original unique-ified\n##      ...5         ...1\n##         x        x...2\n##     x...3        x...3\n##        \"\"         ...4\n## x...1...5        x...5\n\nJB: it is conceivable that this should be under the control of an argument, e.g. dogfood = TRUE, in the (currently unexported) function that does this\n\n2.5.3 When is minimal better than unique?\nWhy would you ever want to import a tibble and enforce only minimal names, instead of unique? Sometimes the first row of a data source – allegedly variable names – actually contains data and the resulting tibble will be reshaped with, e.g., tidyr::gather(). In this case, it is better to not munge the names at import. This is a common special case of the “data stored in names” phenomenon.\nIn general, you may want to tolerate minimal names when the dysfunctional names are just an awkward phase that an object is passing through and a more definitive solution is applied downstream.\n\n2.5.4 Ugly, with a purpose\nYou might say that names like x...5 are ugly and you would be right. We’re calling this a feature, not a bug! Names that have been automatically unique-ified by the tidyverse should catch the eye and give the user strong encouragement to take charge of the situation.\n\n2.5.5 Why so many dots?\nThe suffix of ...j, with 3 leading dots, is the result of jointly satisfying multiple requirements. It is important to anticipate a missing name, where the suffix becomes the entire name. We have elected to make the suffix a syntactic name (more below), because non-syntactic names are a frequent cause of unexpected friction for users. This means the suffix can’t be j, .j, or ..j, because all are non-syntactic. It must be ...j.\n\n2.5.6 Why dot(s) in the first place?\nThe underscore _ was also considered when choosing the suffix strategy, but was rejected. Why? Because syntactic names can’t start with an underscore and we want the suffix itself to be syntactic. Also, the dot . is already used by base R’s make.names() to replace invalid characters. It seems simpler and, therefore, better to use the same character, in the same way, as much as possible in name repair. We use the dot ., we put it at the front, as many times as necessary."
  },
  {
    "objectID": "names.html#universal-names",
    "href": "names.html#universal-names",
    "title": "\n2  Names attribute\n",
    "section": "\n2.6 Universal names",
    "text": "2.6 Universal names\nUniversal names are unique, in the sense described above, and syntactic, in the normal R sense. Universal names are appealing because they play nicely with base R and tidyverse functions that accept unquoted variable names.\n\n2.6.1 Syntactic names\nA syntactic name in R:\n\nConsists of letters, numbers, and the dot . or underscore _ characters.\nStarts with a letter or starts with a dot . followed by anything but a number.\nIs not a reserved word, such as if or function or TRUE.\nIs not ..., R’s special ellipsis or “dots” construct.\nIs not of the form ..j, where j is a number.\n\nSee R’s documentation for Reserved words and Quotes, specifically the section on names and identifiers.\nA syntactic name can be used “as is” in code. For example, it does not require quoting in order to work with non-standard evaluation, such as list indexing via $, in a formula, or in packages like dplyr and ggplot2.\n\n## a syntactic name doesn't require quoting\nx &lt;- tibble::tibble(.else = \"else?!\")\nx$.else\n#&gt; [1] \"else?!\"\ndplyr::select(x, .else)\n#&gt; # A tibble: 1 × 1\n#&gt;   .else \n#&gt;   &lt;chr&gt; \n#&gt; 1 else?!\n\n\n## use a non-syntactic name\nx &lt;- tibble::tibble(`else` = \"else?!\")\n\n## this code does not parse\n# x$else\n# dplyr::select(x, else)\n\n## a non-syntacitic name requires quoting\nx$`else`\n#&gt; [1] \"else?!\"\ndplyr::select(x, `else`)\n#&gt; # A tibble: 1 × 1\n#&gt;   `else`\n#&gt;   &lt;chr&gt; \n#&gt; 1 else?!\n\nNote that being syntactic is a property of an individual name.\n\n2.6.2 Making an individual name syntactic\nThere are many ways to fix a non-syntactic name. Here’s how our logic compares to base::make.names() for a single name:\n\nSame: Definition of what is syntactically valid.\n\nClaim: If syn_name is a name that we have made syntactic, then syn_name == make.names(syn_name). If you find a counterexample, tell us!\n\n\nSame: An invalid character is replaced with a dot ..\nDifferent: We always fix a name by prepending a dot .. base::make.names() sometimes prefixes with X and at other times appends a dot ..\n\nThis means we turn ... into .... and ..j into ...j, where j is a number. base::make.names() does not modify ... or ..j, which could be regarded as a bug (?).\n\n\nDifferent: We treat NA and \"\" the same: both become .. This is because we first make names minimal. base::make.names() turns NA into \"NA.\" and \"\" into \"X\".\n\nExamples of the tidyverse approach to making individual names syntactic versus base::make.names():\n\n## Original Syntactic name    Result of\n##     name    (tidyverse) make.names()\n##       \"\"              .            X\n##       NA              .          NA.\n##      (y)            .y.         X.y.\n##       _z            ._z          X_z\n##     .2fa          ..2fa        X.2fa\n##    FALSE         .FALSE       FALSE.\n##      ...           ....          ...\n##      ..3           ...3          ..3\n\n\nCurrently implemented in the unexported function tibble:::make_syntactic().\n\n2.6.3 Why universal?\nNow we can state the motivation for universal names, which have the group-wise property of being unique and the element-wise property of being syntactic.\nIn practice, if you want syntactic names, you probably also want them to be unique. You need both in order to refer to individual elements easily, without ambiguity and without quoting.\nUniversal names can be requested in the tidyverse via .name_repair = \"universal\", in functions that expose name repair.\n\n2.6.4 Making names universal\nUniversal names are implemented as a variation on unique names. Basically, suffixes are stripped and ... is replaced with \"\". These draft names are transformed with tibble:::make_syntactic() (this step is omitted for unique names). Then ...j suffixes are appended as necessary.\nNote that suffix stripping and the substitution of \"\" for ... happens before the draft names are made syntactic. So, although tibble:::make_syntactic turns ... into ...., universal or unique name repair will turn ... into something of the form ...j."
  },
  {
    "objectID": "names.html#messaging-user-about-name-repair",
    "href": "names.html#messaging-user-about-name-repair",
    "title": "\n2  Names attribute\n",
    "section": "\n2.7 Messaging user about name repair",
    "text": "2.7 Messaging user about name repair\nName repair should be communicated to the user. Here’s how tibble messages:\n\nx &lt;- tibble::tibble(\n  x = 1, x = 2, `a1:` = 3, `_x_y}` = 4,\n  .name_repair = \"universal\"\n)\n#&gt; New names:\n#&gt; • `x` -&gt; `x...1`\n#&gt; • `x` -&gt; `x...2`\n#&gt; • `a1:` -&gt; `a1.`\n#&gt; • `_x_y}` -&gt; `._x_y.`"
  },
  {
    "objectID": "call-data-details.html#whats-the-pattern",
    "href": "call-data-details.html#whats-the-pattern",
    "title": "3  Name all but the most important arguments",
    "section": "\n3.1 What’s the pattern?",
    "text": "3.1 What’s the pattern?\nWhen calling a function, you should name all but the most important arguments. For example:\n\ny &lt;- c(1:10, NA)\nmean(y, na.rm = TRUE)\n#&gt; [1] 5.5\n\nNever use partial matching, like below. Partial matching was useful in the early days of R because when you were doing a quick and dirty interactive analysis you could save a little time by shortening argument names. However, today, most R editing environments support autocomplete so partial matching only saves you a single keystroke, and it makes code substantially harder to read.\n\nmean(y, n = TRUE)\n#&gt; [1] 5.5\n\nAvoid relying on position matching with empty arguments:\n\nmean(y, , TRUE)\n#&gt; [1] 5.5\n\nAnd don’t name arguments that can you expect users to be familiar with:\n\nmean(x = y)\n#&gt; [1] NA\n\nYou can make R give you are warning that you’re using a partially named argument with a special option. Call usethis::use_partial_warnings() to make this the default for all R sessions.\n\noptions(warnPartialMatchArgs = TRUE)\nmean(x = 1:10, n = FALSE)\n#&gt; Warning in mean.default(x = 1:10, n = FALSE): partial argument match of 'n' to\n#&gt; 'na.rm'\n#&gt; [1] 5.5"
  },
  {
    "objectID": "call-data-details.html#why-is-this-useful",
    "href": "call-data-details.html#why-is-this-useful",
    "title": "3  Name all but the most important arguments",
    "section": "\n3.2 Why is this useful?",
    "text": "3.2 Why is this useful?\nI think it’s reasonable to assume that the reader knows what a function does then they know what the one or two most important arguments are, and repeating their names just takes up space without aiding communication. For example, it’s reasonable to assume that people can remember that the first argument to log() is x and the first two arguments to dplyr::left_join() are x and y.\nHowever, I don’t think that most people will remember more than the one or two most important arguments, so you should name the rest. For example, I don’t think that most people know that the second argument to mean() is trim or that the second argument to median() is na.rm even though I expect most people to know what the first arguments are. Spelling out the names makes it easier to understand when others (including future you) are reading the code."
  },
  {
    "objectID": "call-data-details.html#what-are-the-exceptions",
    "href": "call-data-details.html#what-are-the-exceptions",
    "title": "3  Name all but the most important arguments",
    "section": "\n3.3 What are the exceptions?",
    "text": "3.3 What are the exceptions?\nThere are two main exceptions to this principle: when teaching functions and when one argument is particularly long.\nWhen teaching a function for the first time, you can’t expect people to know what the arguments are, so it make sense to supply all names to help people understand exactly what’s going on. For example, in R for Data Science when we introduce ggplot2 we write code like:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point()\n\nAt the end of the chapter, we assume that the reader is familiar with the basic structure and so the rest of the book uses the style recommended here:\n\nggplot(mpg, aes(`displ, hwy)) + \n  geom_point()\n\nThere are also the occasional case when the first argument might be quite long, and there’s a couple of short options that you also want to set. If the long argument comes first, you may have to re-interpret what the function is doing when you finally hit the options. I think this comes up most often when an argument usually receives code inside of {} but it can crop up when manually generating data too.\n\nwriteLines(con = \"test.txt\", c(\n  \"line1\",\n  \"line2\",\n  \"line3\"\n))\n\nexpect_snapshot(error = TRUE, {\n  line1\n  line2\n  line3\n})"
  },
  {
    "objectID": "function-names.html#nouns-vs-verbs",
    "href": "function-names.html#nouns-vs-verbs",
    "title": "\n4  Function names\n",
    "section": "\n4.1 Nouns vs verbs",
    "text": "4.1 Nouns vs verbs\nIn general, prefer verbs. Use imperative mood: mutate() not mutated(), mutates(), or mutating(); do() not did(), does(), doing(), hide() not hid(), hides(), or hiding().\nException: noun-y interfaces where you’re building up a complex object like ggplot2 or recipes (verb-y interface in ggvis was a mistake).\nNouns should be singular (geom_point() not geom_points()), simply because the plurisation rules in English are complex."
  },
  {
    "objectID": "function-names.html#function-families",
    "href": "function-names.html#function-families",
    "title": "\n4  Function names\n",
    "section": "\n4.2 Function families",
    "text": "4.2 Function families\nUse prefixes to group functions together based on common input or common purpose. Prefixes are better than suffixes because of auto-complete. Examples: ggplot2, purrr. Counter example: shiny.\nNot sure about common prefixes for a package. Works well for stringr (esp. with stringi), forcats, xml2, and rvest. But there’s only a limited number of short prefixes and I think it would break down if every package did it.\nUse suffixes for variations on a theme (e.g. map_int(), map_lgl(), map_dbl(); str_locate(), str_locate_all().)\nStrive for thematic unity in related functions. Can you make related fuctions rhyme? Or have the same number of letters? Or similar background (i.e. all Germanic origins vs. French)."
  },
  {
    "objectID": "function-names.html#length",
    "href": "function-names.html#length",
    "title": "\n4  Function names\n",
    "section": "\n4.3 Length",
    "text": "4.3 Length\nErr on the side of too long rather than too short (reading is generally more important than writing). Autocomplete will mostly take care of the nuisance and you can always shorten later if you come up with a better name. (But hard to make long later, and you may take up a good word that is a lot of work to reclaim later).\nLength of name should be inversely proportional to frequency of usage. Reserve very short words for functions that are likely to be used very frequently."
  },
  {
    "objectID": "function-names.html#conflicts",
    "href": "function-names.html#conflicts",
    "title": "\n4  Function names\n",
    "section": "\n4.4 Conflicts",
    "text": "4.4 Conflicts\nYou can’t expect to avoid conflicts with every existing CRAN package, but you should strive to avoid conflicts with “nearby” packages (i.e. packages that are commonly used with your package)."
  },
  {
    "objectID": "function-names.html#techniques",
    "href": "function-names.html#techniques",
    "title": "\n4  Function names\n",
    "section": "\n4.5 Techniques",
    "text": "4.5 Techniques\n\nThesaurus\nList of common verbs\nRhyming dictionary"
  },
  {
    "objectID": "function-names.html#other-good-advice",
    "href": "function-names.html#other-good-advice",
    "title": "\n4  Function names\n",
    "section": "\n4.6 Other good advice",
    "text": "4.6 Other good advice\n\nI Shall Call It.. SomethingManager\nThe Poetry of Function Naming"
  },
  {
    "objectID": "inputs-explicit.html#whats-the-problem",
    "href": "inputs-explicit.html#whats-the-problem",
    "title": "5  Make inputs explicit",
    "section": "\n5.1 What’s the problem?",
    "text": "5.1 What’s the problem?\nA function is easier to understand if its output depends only on its inputs (i.e. its arguments). If a function returns different results with the same inputs, then some inputs must be implicit, typically because the function relies on an option or some locale setting. Implicit inputs are not always bad, as some functions like Sys.time(), read.csv(), and the random number generators, fundamentally depend on them. But they should be used as sparingly as possible, and never when not related to the core purpose of the function.\nExplicit arguments make code easier to understand because you can see what will affect the outputs just by reading the code; you don’t need to run it. Implicit arguments can lead to code that returns different results on different computers, and the differences are usually hard to track down."
  },
  {
    "objectID": "inputs-explicit.html#what-are-some-examples",
    "href": "inputs-explicit.html#what-are-some-examples",
    "title": "5  Make inputs explicit",
    "section": "\n5.2 What are some examples?",
    "text": "5.2 What are some examples?\nOne common source of hidden arguments is the use of global options:\n\nHistorically, the worst offender was the stringsAsFactors option which changed how a number of functions1 treated character vectors. This option was part of a multi-year procedure to move R away toward character vectors and away from vectors. You can learn more in stringsAsFactors: An unauthorized biography by Roger Peng and stringsAsFactors = &lt;sigh&gt; by Thomas Lumley.\nlm()’s handling of missing values depends on the global option of na.action. The default is na.omit which drops the missing values prior to fitting the model (which is inconvenient because then the results of predict() don’t line up with the input data.\n\nAnother common source of subtle bugs is relying on the system locale, i.e. the country and language specific settings controlled by your operating system. Relying on the system locale is always done with the best of intentions (you want your code to respect the user’s preferences) but can lead to subtle differences when the same code is run by different people. Here are a few examples:\n\nstrptime() relies on the names of weekdays and months in the current locale. That means strptime(\"1 Jan 2020\", \"%d %b %Y\") will work on computers with an English locale, and fail elsewhere.\n\nas.POSIXct() depends on the current timezone. The following code returns different underlying times when run on different computers:\n\nas.POSIXct(\"2020-01-01 09:00\")\n#&gt; [1] \"2020-01-01 09:00:00 UTC\"\n\n\ntoupper() and tolower() depend on the current locale. It is fairly uncommon for this to cause problems because most languages either use their own character set, or use the same rules for capitalisation as English. However, this behaviour did cause a bug in ggplot2 because internally it takes geom = \"identity\" and turns it into GeomIdentity to find the object that actually does computation. In Turkish, however, the upper case version of i is İ, and Geomİdentity does not exist. This meant that for some time ggplot2 did not work on Turkish computers.\nsort() and order() rely on the lexicographic order (i.e. how different alphabets sort their letters) defined by the current locale. lm() automatically converts character vectors to factors with factor(), which uses order(), which means that it’s possible for the coefficients to vary2 if your code is run in a different country!"
  },
  {
    "objectID": "inputs-explicit.html#how-can-i-remediate-the-problem",
    "href": "inputs-explicit.html#how-can-i-remediate-the-problem",
    "title": "5  Make inputs explicit",
    "section": "\n5.3 How can I remediate the problem?",
    "text": "5.3 How can I remediate the problem?\nAt some level, implicit inputs are easy to avoid when creating new functions: just don’t use the locale or global options! But it’s easy for such problems to creep in indirectly, when you call a function not knowing that it has hidden inputs. The best way to prevent that is to consult the list of common offenders provided above.\n\n5.3.1 Make an option explicit\nIf you want depend on an option or locale, make sure it’s an explicit argument. Such arguments generally should not affect computation (Chapter 15), just side-effects like printed output or status messages. If they do affect results, follow Chapter 14 to make sure the user knows what’s happening. For example, lets take as.POSIXct() which basically looks something like this:\n\nas.POSIXct &lt;- function(x, tz = \"\") {\n  base::as.POSIXct(x, tz = tz)\n}\nas.POSIXct(\"2020-01-01 09:00\")\n#&gt; [1] \"2020-01-01 09:00:00 UTC\"\n\nThe tz argument is present, but it’s not obvious that \"\" means the current time zone. Let’s first make that explicit:\n\nas.POSIXct &lt;- function(x, tz = Sys.timezone()) {\n  base::as.POSIXct(x, tz = tz)\n}\nas.POSIXct(\"2020-01-01 09:00\")\n#&gt; [1] \"2020-01-01 09:00:00 UTC\"\n\nSince this is an important default whose value can change, we also print it out if the user hasn’t explicitly set it:\n\nas.POSIXct &lt;- function(x, tz = Sys.timezone()) {\n  if (missing(tz)) {\n    message(\"Using `tz = \\\"\", tz, \"\\\"`\")\n  }\n  base::as.POSIXct(x, tz = tz)\n}\nas.POSIXct(\"2020-01-01 09:00\")\n#&gt; Using `tz = \"UTC\"`\n#&gt; [1] \"2020-01-01 09:00:00 UTC\"\n\nSince most people don’t like lots of random output this provides a subtle incentive to supply the timezone:\n\nas.POSIXct(\"2020-01-01 09:00\", tz = \"America/Chicago\")\n#&gt; [1] \"2020-01-01 09:00:00 CST\"\n\n\n5.3.2 Temporarily adjust global state\nIf you’re calling a function with implicit arguments and those implicit arguments are causing problems with your code, you can always work around them by temporarily changing the global state which it uses. The easiest way to do so is to use the withr package, which provides a variety of tools to change temporarily change global state."
  },
  {
    "objectID": "inputs-explicit.html#see-also",
    "href": "inputs-explicit.html#see-also",
    "title": "5  Make inputs explicit",
    "section": "\n5.4 See also",
    "text": "5.4 See also\n\n\nChapter 15 and Chapter 14: how to make an option as explicit as possible.\n\nChapter 33: where a function changes global state in a surprising way."
  },
  {
    "objectID": "inputs-explicit.html#footnotes",
    "href": "inputs-explicit.html#footnotes",
    "title": "5  Make inputs explicit",
    "section": "",
    "text": "Such as data.frame(), as.data.frame(), and read.csv()↩︎\nPredictions and other diagnostics won’t be affected, but you’re likely to be surprised that your coefficients are different.↩︎"
  },
  {
    "objectID": "important-args-first.html#whats-the-pattern",
    "href": "important-args-first.html#whats-the-pattern",
    "title": "6  Put the most important arguments first",
    "section": "\n6.1 What’s the pattern?",
    "text": "6.1 What’s the pattern?\nIn a function call, the most important arguments should come first. As a general rule, the most important arguments will be the ones that are used most often, but that’s often hard to tell until your function has existed in the wild for a while. Fortunately, there are a few rules of thumb that can help:\n\nIf the output is a transformation of an input (e.g. log(), stringr::str_replace(), dplyr::left_join()) then that argument the most important.\nOther arguments that determine the type or shape of the output are typically very important.\nOptional arguments (i.e. arguments with a default) are the least important, and should come last.\n\nThis convention makes it easy to understand the structure of a function at a glance: the more important an argument is, the earlier you’ll see it. When the output is very strongly tied to an input, putting that argument first also ensures that your function works well with the pipe, leading to code that focuses on the transformations rather than the object being transformed."
  },
  {
    "objectID": "important-args-first.html#what-are-some-examples",
    "href": "important-args-first.html#what-are-some-examples",
    "title": "6  Put the most important arguments first",
    "section": "\n6.2 What are some examples?",
    "text": "6.2 What are some examples?\nThe vast majority of functions get this right, so we’ll pick on a few examples which I think get it wrong:\n\nI think the arguments to base R string functions (grepl(), gsub(), etc) are in the wrong order because they consistently make the regular expression (pattern) the first argument, rather than the character vector being manipulated (x).\nThe first two arguments to lm() are formula and data. I’d argue that data should be the first argument; while it doesn’t affect the shape of the output which is always an lm S3 object, it does affect the shape of many important functions like predict(). However, the designers of lm() wanted data to be optional, so you could still fit models even if you hadn’t collected the individual variables into a data frame. Because formula is required and data is not, this means that formula had to come first.\n\nThe first two arguments to ggplot() are data and mapping. Both data and mapping are required for every plot, so why make data first? I picked this ordering because in most plots there’s one dataset shared across all layers and only the mapping changes.\nOn the other hand, the layer functions, like geom_point(), flip the order of these arguments because in an individual layer you’re more likely to specify mapping than data, and in many cases if you do specify data you’ll want mapping as well. This makes these the argument order inconsistent with ggplot(), but overall supports the most common use cases.\n\nggplot2 functions work by creating an object that is then added on to a plot, so the plot, which is really the most important argument, is not obvious at all. ggplot2 works this way in part because it was written before the pipe was discovered, and the best way I came up to define plots from left to right was to rely on + (so-called operator overloading). As an interesting historical fact, ggplot (the precursor to ggplot2) actually works great with the pipe, and a couple of years ago I bought it back to life as ggplot1."
  },
  {
    "objectID": "important-args-first.html#how-do-i-remediate-past-mistakes",
    "href": "important-args-first.html#how-do-i-remediate-past-mistakes",
    "title": "6  Put the most important arguments first",
    "section": "\n6.3 How do I remediate past mistakes?",
    "text": "6.3 How do I remediate past mistakes?\nGenerally, it is not possible to change the order of the first few arguments because it will break existing code (since these are the arguments that are mostly likely to be used unnamed). This means that the only real solution is to dperecate the entire function and replace it with a new one. Because this is invasive to the user, it’s best to do sparingly: if the mistake is minor, you’re better off waiting until you’ve collected other problems before fixing it. For example, take tidyr::gather(). It has a number of problems with its design, including the argument order, that makes it harder to use. Because it wasn’t possible to easily fix this mistake, we accumulated other gather() problems for several years before fixing them all at once in pivot_longer()."
  },
  {
    "objectID": "important-args-first.html#see-also",
    "href": "important-args-first.html#see-also",
    "title": "6  Put the most important arguments first",
    "section": "\n6.4 See also",
    "text": "6.4 See also\n\n\nChapter 8: If the function uses …, it should come in between the required and optional arguments."
  },
  {
    "objectID": "required-no-defaults.html#whats-the-pattern",
    "href": "required-no-defaults.html#whats-the-pattern",
    "title": "7  Required args shouldn’t have defaults",
    "section": "\n7.1 What’s the pattern?",
    "text": "7.1 What’s the pattern?\nRequired arguments shouldn’t have defaults; optional arguments should have defaults. In other words, an argument should have a default if and only if it’s optional.\nThis simple convention ensures that you can tell which arguments are optional and which arguments are required from a glance at the function signature. Otherwise you need to rely on a careful reading of documentation. Additionally, if you don’t follow this convention and want to provide helpful error messages, you’ll need to implement them yourself rather than relying on R’s defaults."
  },
  {
    "objectID": "required-no-defaults.html#what-are-some-examples",
    "href": "required-no-defaults.html#what-are-some-examples",
    "title": "7  Required args shouldn’t have defaults",
    "section": "\n7.2 What are some examples?",
    "text": "7.2 What are some examples?\nThis is a straightforward convention that the vast majority of functions follow. There are a few exceptions that exist in base R, mostly for historical reasons. Here are a couple of examples:\n\n\nIn sample() neither x not size has a default value:\n\nargs(sample)\n#&gt; function (x, size, replace = FALSE, prob = NULL) \n#&gt; NULL\n\nThis suggests that size is required, but it’s actually optional:\n\nsample(1:4)\n#&gt; [1] 3 1 2 4\nsample(4)\n#&gt; [1] 3 1 2 4\n\n\n\nlm() does not have defaults for formula, data, subset, weights, na.action, or offset.\n\nargs(lm)\n#&gt; function (formula, data, subset, weights, na.action, method = \"qr\", \n#&gt;     model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, \n#&gt;     contrasts = NULL, offset, ...) \n#&gt; NULL\n\nBut only formula is actually required:\n\nx &lt;- 1:5\ny &lt;- 2 * x + 1 + rnorm(length(x))\nlm(y ~ x)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)            x  \n#&gt;      0.3951       2.3288\n\n\n\nIn the tidyverse, one function that fails to follow this pattern is ggplot2::geom_abline(), slope and intercept don’t have defaults but are not required. If you don’t supply them they default to slope = 1 and intercept = 0, or are taken from aes() if they’re provided there. This is a mistake caused by trying to have geom_abline() do too much — it can be both used as an annotation (i.e. with a single slope and intercept) or used to draw multiple lines from data (i.e. with one line for each row)."
  },
  {
    "objectID": "required-no-defaults.html#how-do-i-use-the-pattern",
    "href": "required-no-defaults.html#how-do-i-use-the-pattern",
    "title": "7  Required args shouldn’t have defaults",
    "section": "\n7.3 How do I use the pattern?",
    "text": "7.3 How do I use the pattern?\nThis pattern is generally easy to follow: if you don’t use missing() it’s very hard to do this by mistake."
  },
  {
    "objectID": "required-no-defaults.html#how-do-i-remediate-past-mistakes",
    "href": "required-no-defaults.html#how-do-i-remediate-past-mistakes",
    "title": "7  Required args shouldn’t have defaults",
    "section": "\n7.4 How do I remediate past mistakes?",
    "text": "7.4 How do I remediate past mistakes?\nIf an argument is required, remove the default argument. If an argument is optional, either set it to the default value, or if the computation is complicated, set it to NULL and then compute inside the body of the function."
  },
  {
    "objectID": "required-no-defaults.html#see-also",
    "href": "required-no-defaults.html#see-also",
    "title": "7  Required args shouldn’t have defaults",
    "section": "\n7.5 See also",
    "text": "7.5 See also\nThere are some exceptions to this rule when some arguments are only required sometimes:\n\nChapter 24: mutually exclusive arguments shouldn’t have defaults even though one is required.\nChapter 25: compound arguments allow one argument to occasionally take the place of multiple required arguments."
  },
  {
    "objectID": "dots-after-required.html#whats-the-pattern",
    "href": "dots-after-required.html#whats-the-pattern",
    "title": "8  Put … after required arguments",
    "section": "\n8.1 What’s the pattern?",
    "text": "8.1 What’s the pattern?\nIf you use … in a function, put it after the required arguments and before the optional arguments.\nThis has two positive impacts:\n\nIt forces the user of your function to fully name optional arguments, because arguments that come after ... are never matched by position or by partial name. We believe that using full names for optional arguments is good practice because it makes code easier to read.\nThis in turn means that uou can easily add new optional arguments or change the order of existing arguments without affecting existing code."
  },
  {
    "objectID": "dots-after-required.html#what-are-some-examples",
    "href": "dots-after-required.html#what-are-some-examples",
    "title": "8  Put … after required arguments",
    "section": "\n8.2 What are some examples?",
    "text": "8.2 What are some examples?\nThe arguments to mean() are x, trim, na.rm and …. This means that you can write code like this:\n\nx &lt;- c(1, 2, 10, NA)\nmean(x, , TRUE)\n#&gt; [1] 4.333333\nmean(x, n = TRUE, t = 0.1)\n#&gt; [1] 4.333333\n\nNot only does this allow for confusing code1, it also makes it hard to later change the order of these arguments, or introduce new arguments that might be more important.\nIf mean() instead placed … before trim and na.rm, like mean2()2 below, then you must fully name each argument:\n\nmean2 &lt;- function(x, ..., na.rm = FALSE, trim = 0) {\n  mean(x, ..., na.rm = na.rm, trim = trim)\n}\n\nmean2(x, na.rm = TRUE)\n#&gt; [1] 4.333333\nmean2(x, na.rm = TRUE, trim = 0.1)\n#&gt; [1] 4.333333"
  },
  {
    "objectID": "dots-after-required.html#how-do-i-remediate-past-mistakes",
    "href": "dots-after-required.html#how-do-i-remediate-past-mistakes",
    "title": "8  Put … after required arguments",
    "section": "\n8.3 How do I remediate past mistakes?",
    "text": "8.3 How do I remediate past mistakes?\nIt’s straightforward to fix a function where you’ve put ... in the wrong place: you just need to change the argument order and use rlang::check_dots_used() to check that no arguments are lost (learn more in Chapter 19). This is a breaking change, but it tends to affect relatively little code because most people do fully name optional arguments.\nWe can use this approach to make a safer version of mean():\n\nmean3 &lt;- function(x, ..., na.rm = FALSE, trim = 0) {\n  rlang::check_dots_used()\n  mean(x, ..., na.rm = na.rm, trim = trim)\n}\n\nmean3(x, , TRUE)\n#&gt; Error in `mean3()`:\n#&gt; ! Arguments in `...` must be used.\n#&gt; ✖ Problematic argument:\n#&gt; • ..1 = TRUE\n#&gt; ℹ Did you misspell an argument name?\n\nmean3(x, n = TRUE, t = 0.1)\n#&gt; Error in `mean3()`:\n#&gt; ! Arguments in `...` must be used.\n#&gt; ✖ Problematic arguments:\n#&gt; • n = TRUE\n#&gt; • t = 0.1\n#&gt; ℹ Did you misspell an argument name?"
  },
  {
    "objectID": "dots-after-required.html#see-also",
    "href": "dots-after-required.html#see-also",
    "title": "8  Put … after required arguments",
    "section": "\n8.4 See also",
    "text": "8.4 See also\n\n\nChapter 17: if … is a required argument because it’s used to combine an arbitrary number of objects in a data structure.\n\nChapter 19: to ensure that arguments to … never go silently missing."
  },
  {
    "objectID": "dots-after-required.html#footnotes",
    "href": "dots-after-required.html#footnotes",
    "title": "8  Put … after required arguments",
    "section": "",
    "text": "As much as we recommended people don’t write code like this, you know someone will!↩︎\nNote that I moved na.rm = TRUE in front of trim because I believe na.rm is the more important argument because it’s used vastly more often than trim and I’m following Chapter 6.↩︎"
  },
  {
    "objectID": "defaults-short-and-sweet.html#whats-the-pattern",
    "href": "defaults-short-and-sweet.html#whats-the-pattern",
    "title": "9  Keep defaults short and sweet",
    "section": "\n9.1 What’s the pattern?",
    "text": "9.1 What’s the pattern?\nDefault values should be short and sweet. Avoid large or complex calculations in the default values, instead using NULL or helper function to where more calculation is needed.\nThis keeps the function specification focussed on the big picture (i.e. what are the arguments and are they required or not) rather than the details of the defaults."
  },
  {
    "objectID": "defaults-short-and-sweet.html#what-are-some-examples",
    "href": "defaults-short-and-sweet.html#what-are-some-examples",
    "title": "9  Keep defaults short and sweet",
    "section": "\n9.2 What are some examples?",
    "text": "9.2 What are some examples?\nThe following examples, drawn from base R, illustrate some functions that don’t follow this pattern:\n\nsample.int() uses a complicated rule to determine whether or not to use a faster hash based method that’s only applicable in some circumstances: useHash = (!replace && is.null(prob) && size &lt;= n/2 && n &gt; 1e+07))\nexists(), which figures out if a variable exists in a given environment, uses a complex default to determine which environment to look in if not specifically provided: envir = (if (missing(frame)) as.environment(where) else sys.frame(frame)) (NB: ?exists cheats and hides the long default in the documentation.)\n\nreshape() has a very long default argument: the split argument is one of two possible lists depending on the value of the sep argument:\n\nreshape &lt;- function(\n    ...,\n    split = if (sep == \"\") {\n      list(regexp = \"[A-Za-z][0-9]\", include = TRUE)\n    } else {\n      list(regexp = sep, include = FALSE, fixed = TRUE)\n    }\n) {}"
  },
  {
    "objectID": "defaults-short-and-sweet.html#how-do-i-use-it",
    "href": "defaults-short-and-sweet.html#how-do-i-use-it",
    "title": "9  Keep defaults short and sweet",
    "section": "\n9.3 How do I use it?",
    "text": "9.3 How do I use it?\nThere are three approaches:\n\nSet the default value to NULL and calculate the default only when the argument is NULL. Providing a default of NULL signals that the argument is optional (Chapter 7) but that the default requires some calculation.\nIf the calculation is complex, and the user might find it useful in other scenarios, compute it with an exported function that documents exactly what happens.\nIf NULL is meaningful, so you can’t use the first approach, use a “sentinel” object instead.\n\n\n9.3.1 NULL default\nThe most common approach is to use NULL as a sentinel value that indicates that the argument is optional, but non-trivial. This pattern is made substantially more elegant with the infix %||% operator. You can either get it by importing it from rlang, or copying and pasting it in to your utils.R:\n\n`%||%` &lt;- function(x, y) if (is.null(x)) y else x\n\nThis allows you to write code like this (extracted from ggplot2::geom_bar()). It computes the width by first looking at the data, then in the parameters, finally falling back to computing it from the resolution of the x variable:\n\nwidth &lt;- data$width %||% params$width %||% (resolution(data$x, FALSE) * 0.9)\n\nOr this code from the colourbar legend: it finds the horizontal justification by first looking in the guide settings, then in the specific theme setting, then then title element, finally using 0 if nothing else is set:\n\ntitle.hjust &lt;- guide$title.hjust %||% \n  theme$legend.title.align %||% \n  title.theme$hjust %||% \n  0\n\nAs you can see, %||% is particularly well suited to arguments where the default value is found through a cascading system of fallbacks.\nDon’t use %||% for more complex examples where the individual clauses can’t fit on their own line. For example in reshape() I would set split = NULL and then write:\n\nif (is.null(split)) {\n  if (sep == \"\") {\n    split &lt;- list(regexp = \"[A-Za-z][0-9]\", include = TRUE)\n  } else {\n    split &lt;- list(regexp = sep, include = FALSE, fixed = TRUE)\n  }\n}\n\n\n9.3.2 Helper function\nFor more complicated cases, you’ll probably want to pull the code that computes the default out into a separate function, and in many cases you’ll want to export (and document) the function.\nA good example of this pattern is readr::show_progress(): it’s used in every read_ function in readr and it’s sufficiently complicated that you don’t want to copy and paste it between functions. It’s also nice to document it in its own file, rather than cluttering up file reading functions with incidental details.\n\n9.3.3 Sentinel value\nSometimes a default argument has a complex calculation that you don’t want to include in arguments list. You’d normally use NULL to indicate that it’s calculated by default, but NULL is a meaningful option. In that case, you can use a sentinel object.\n\nstr(ggplot2::waiver())\n#&gt;  list()\n#&gt;  - attr(*, \"class\")= chr \"waiver\"\n\nstr(purrr::done())\n#&gt; List of 1\n#&gt;  $ : symbol \n#&gt;  - attr(*, \"class\")= chr [1:2] \"rlang_box_done\" \"rlang_box\"\n#&gt;  - attr(*, \"empty\")= logi TRUE\n\nstr(rlang::zap())\n#&gt;  list()\n#&gt;  - attr(*, \"class\")= chr \"rlang_zap\"\n\nTake purrr::reduce(): it has an optional details argument called init. When supplied, it serves as the initial value for the computation. But any value (including NULL) can a valid value. And using a sentinel value for this one case seemed like overkill."
  },
  {
    "objectID": "defaults-short-and-sweet.html#how-do-i-remediate-existing-problems",
    "href": "defaults-short-and-sweet.html#how-do-i-remediate-existing-problems",
    "title": "9  Keep defaults short and sweet",
    "section": "\n9.4 How do I remediate existing problems?",
    "text": "9.4 How do I remediate existing problems?\nIf you have a function with a long default, you can use any of the three approaches above to remediate it. As long as you don’t accidentally change the default value, this does not affect the function interface. Make sure you have a test for the default operation of the function before embarking on this change.\n\n# BEFORE\nsample.int &lt;- function(n, \n                       size = n, \n                       replace = FALSE, \n                       prob = NULL, \n                       useHash = (!replace && is.null(prob) && size &lt;= n/2 && n &gt; 1e+07)\n                       ) {\n  \n  ...\n}\n\n# AFTER\nsample.int &lt;- function(n, size = n, replace = FALSE, prob = NULL, useHash = NULL) {\n  useHash &lt;- useHash %||% (!replace && is.null(prob) && size &lt;= n/2 && n &gt; 1e+07)\n\n  ...\n}"
  },
  {
    "objectID": "enumerate-options.html#whats-the-pattern",
    "href": "enumerate-options.html#whats-the-pattern",
    "title": "10  Enumerate possible options",
    "section": "\n10.1 What’s the pattern?",
    "text": "10.1 What’s the pattern?\nIf the possible values of an argument are a small set of strings, set the default argument to the set of possible values, and then use match.arg() or rlang::arg_match() in the function body. This convention advertises to the user what the possible values, and makes it easy to generate an informative error message for inappropriate inputs."
  },
  {
    "objectID": "enumerate-options.html#what-are-some-examples",
    "href": "enumerate-options.html#what-are-some-examples",
    "title": "10  Enumerate possible options",
    "section": "\n10.2 What are some examples?",
    "text": "10.2 What are some examples?\n\nIn difftime(), units can be any one of “auto”, “secs”, “mins”, “hours”, “days”, or “weeks”.\nIn format(), justify can be “left”, “right”, “center”, or “none”.\nIn trimws(), you can choose which side to remove whitespace from: “both”, “left”, or “right”.\nIn rank(), you can select the ties.method from one of “average”, “first”, “last”, “random”, “max”, or “min”.\nIn RSiteSearch(), you can restrict results to be “functions”, “vignettes”, “views”, or any combination of the three."
  },
  {
    "objectID": "enumerate-options.html#why-is-it-important",
    "href": "enumerate-options.html#why-is-it-important",
    "title": "10  Enumerate possible options",
    "section": "\n10.3 Why is it important?",
    "text": "10.3 Why is it important?\nThis convention makes it possible to advertise the possible set of values for an argument. The advertisement happens in the function specification, so you see in tooltips and autocomplete, without having to look at the documentation."
  },
  {
    "objectID": "enumerate-options.html#how-do-i-use-it",
    "href": "enumerate-options.html#how-do-i-use-it",
    "title": "10  Enumerate possible options",
    "section": "\n10.4 How do I use it?",
    "text": "10.4 How do I use it?\nTo use this technique, set the default value to a character vector, where the first value is the default. Inside the function, use match.arg() or rlang::arg_match() which checks that the value comes from the known good set. This interface pattern is often coupled with an implementation that uses switch().\nTake rank(), for example. The heart of its implementation looks like this:\n\nrank &lt;- function(x, \n                 ties.method = \n                  c(\"average\", \"first\", \"last\", \"random\", \"max\", \"min\")\n                 ) {\n  \n  ties.method &lt;- match.arg(ties.method)\n  \n  switch(ties.method, \n    average = , \n    min = , \n    max = .Internal(rank(x, length(x), ties.method)), \n    first = sort.list(sort.list(x)),\n    last = sort.list(rev.default(sort.list(x, decreasing = TRUE))), \n    random = sort.list(order(x, stats::runif(length(x))))\n  )\n}\n\nx &lt;- c(1, 2, 2, 3, 3, 3)\n\nrank(x)\n#&gt; [1] 1.0 2.5 2.5 5.0 5.0 5.0\nrank(x, ties.method = \"first\")\n#&gt; [1] 1 2 3 4 5 6\nrank(x, ties.method = \"min\")\n#&gt; [1] 1 2 2 4 4 4\n\nNote that match.arg() will automatically throw an error if the value is not in the set:\n\nrank(x, ties.method = \"middle\")\n#&gt; Error in match.arg(ties.method): 'arg' should be one of \"average\", \"first\", \"last\", \"random\", \"max\", \"min\"\n\nIt also supports partial matching so that the following code is shorthand for `ties.method = “random”:\n\nrank(x, ties.method = \"r\")\n#&gt; [1] 1 3 2 4 6 5\n\nI generally believe that partial matching is a bad idea, because it makes code harder to read. rlang::arg_match() is an alternative to match.args() that doesn’t support partial matching. Instead it provides a helpful error message:\n\nrank2 &lt;- function(x, \n                 ties.method = \n                  c(\"average\", \"first\", \"last\", \"random\", \"max\", \"min\")\n                 ) {\n  \n  ties.method &lt;- rlang::arg_match(ties.method)\n  rank(x, ties.method = ties.method)\n}\n\nrank2(x, ties.method = \"r\")\n#&gt; Error in `rank2()`:\n#&gt; ! `ties.method` must be one of \"average\", \"first\", \"last\", \"random\",\n#&gt;   \"max\", or \"min\", not \"r\".\n#&gt; ℹ Did you mean \"random\"?\n\n\n10.4.1 How keep defaults short?\nThis technique is a best used when the set of possible values is short. You can see that it’s already getting unwieldy in rank(). If you have a long list of possibilities, there are two options that you could use from Chapter 9. Unfortunately both approaches have major downsides:\n\n\nSet a single default and supply the possible values to match.arg():\n\nrank2 &lt;- function(x, ties.method = \"average\") {\n  ties.method &lt;- match.arg(\n    ties.method, \n    c(\"average\", \"first\", \"last\", \"random\", \"max\", \"min\")\n  )\n}\n\nThe downside of this approach is that you can no longer see which values are permitted, and you’d have to describe them separately in the documentation. You can, however, still see the default value in the function specification.\n\n\nStore the options in an exported function, and use it in the defaults:\n\nties_method &lt;- function() {\n  c(\"average\", \"first\", \"last\", \"random\", \"max\", \"min\")\n}\n\nrank2 &lt;- function(x, ties.method = ties_method()) {\n  ties.method &lt;- match.arg(ties.method)\n}\n\nThe downside of this approach is that when looking at the function spec, you can no longer easily see the default value, or the set of possible values. However, the possible values can easily be found programmatically.\nThis is more worthwhile if you want to share the permitted values across multiple functions. For example stats::p.adjust(), stats::pairwise.prop.test(), stats::pairwise.t.test(), stats::pairwise.wilcox.test() all use p.adjust.method = p.adjust.methods."
  },
  {
    "objectID": "argument-clutter.html#whats-the-problem",
    "href": "argument-clutter.html#whats-the-problem",
    "title": "11  Avoid argument clutter with an options object",
    "section": "\n11.1 What’s the problem?",
    "text": "11.1 What’s the problem?\nIf you have a large number of optional arguments that control the fine details of the operation of a function, it might be worth moving them into a separate “options” argument.\nHaving a large number of less important options makes it harder to see the the most important options."
  },
  {
    "objectID": "argument-clutter.html#what-are-some-examples",
    "href": "argument-clutter.html#what-are-some-examples",
    "title": "11  Avoid argument clutter with an options object",
    "section": "\n11.2 What are some examples?",
    "text": "11.2 What are some examples?\n\n\nA number of base R modelling functions like loess(), glm(), and nls() have control arguments that are paired with a function like loess.control(), glm.control(), and nls.control(). These allow you to modify some rarely defaults, including the number of iterations, and the stopping criteria, and some debugging options.\noptim() uses a less formal version of this structure — while it has a control argument, it doesn’t have a matching optim.control() helper. Instead, you supply a named list with components described in ?optim.\n\nreadr::read_csv() and friends take a locale argument with value created by readr::locale(). This object bundles together a bunch of options related to parsing numbers, dates, and times that vary from country to country.\nreadr::locale() itself has a date_names argument that’s paired with readr::date_names() and readr::date_names_lang() helpers. You typically use it by supplying a two letter locale name (which date_names_lang() uses to look up common languages), but if your language isn’t supported you can use readr::date_names() to individually supply full and abbreviate month and day of week names.\nSomewhat related is the engine specification used by readr, e.g. regex(\".\", multline = TRUE), as discussed in Section 26.3."
  },
  {
    "objectID": "argument-clutter.html#how-do-i-use-this-pattern",
    "href": "argument-clutter.html#how-do-i-use-this-pattern",
    "title": "11  Avoid argument clutter with an options object",
    "section": "\n11.3 How do I use this pattern?",
    "text": "11.3 How do I use this pattern?\nThe simple implement is just to create an object that returns a list:\n\nmy_fun_opts &lt;- function(opt1 = 1, opt2 = 2) {\n  list(\n    opt1 = opt1,\n    opt2 = opt2\n  )\n}\n\nJust this alone is nice because you can document the individual arguments, and auto-complete will remind the user what these less important options include.\nIt’s good practice to add a class to this list so you can give more informative errors if the user supplies the wrong value:\n\nmy_fun_opts &lt;- function(opt1 = 1, opt2 = 2) {\n  structure(\n    list(\n      opt1 = opt1,\n      opt2 = opt2\n    ),\n    class = \"mypackage_my_fun_opts\"\n  )\n}\n\nis_my_fun_opts &lt;- function(x) {\n  inherits(x, \"mypackage_my_fun_opts\")\n}\n\nmy_fun_opts &lt;- function(..., opts = my_fun_opts()) {\n  if (!is_my_fun_opts(opts)) {\n    cli::cli_abort(\"{.arg opts} must be created by {.fun my_fun_opts}.\")\n  }\n}"
  },
  {
    "objectID": "argument-clutter.html#how-do-i-remediate-past-mistakes",
    "href": "argument-clutter.html#how-do-i-remediate-past-mistakes",
    "title": "11  Avoid argument clutter with an options object",
    "section": "\n11.4 How do I remediate past mistakes?",
    "text": "11.4 How do I remediate past mistakes?\nTypically you notice this problem after you have created too many options so you’ll need to carefully remediate by introducing a new options function and paired argument, and then deprecating the old arguments. For example, if your existing function looks like this:\n\nmy_fun &lt;- function(x, y, opt1 = 1, opt2 = 2) {\n  \n}\n\nThen you’ll need to create a my_fun_opts() as above, add an opts argument that uses that as the default. This is a breaking change, so if you want to provide a gradual on-ramp to the new API, for a while you can accept both the individual options and the options object, deprecating the individual options:\n\nmy_fun &lt;- function(x, y, opts = my_fun_opts(), opt1 = deprecated(), opt2 = deprecated()) {\n  \n  if (lifecycle::is_present(opt1)) {\n    lifecycle::deprecate_warn(\"1.0.0\", \"my_fun(opt1)\", \"my_fun_opts(opt1)\")\n    opts$opt1 &lt;- opt1\n  }\n  if (lifecycle::is_present(opt2)) {\n    lifecycle::deprecate_warn(\"1.0.0\", \"my_fun(opt2)\", \"my_fun_opts(opt2)\")\n    opts$opt2 &lt;- opt2\n  }\n}\n\nThen in a future release you can remove the old arguments."
  },
  {
    "objectID": "argument-clutter.html#see-also",
    "href": "argument-clutter.html#see-also",
    "title": "11  Avoid argument clutter with an options object",
    "section": "\n11.5 See also",
    "text": "11.5 See also"
  },
  {
    "objectID": "cs-rep.html#what-does-rep-do",
    "href": "cs-rep.html#what-does-rep-do",
    "title": "12  Case study: rep()",
    "section": "\n12.1 What does rep() do?",
    "text": "12.1 What does rep() do?\nrep() is an extremely useful base R function that repeats a vector x in various ways. It has three details arguments: times, each, and length.out1 that interact in complicated ways. Let’s explore the basics first:\n\nx &lt;- c(1, 2, 4)\n\nrep(x, times = 3)\n#&gt; [1] 1 2 4 1 2 4 1 2 4\nrep(x, length.out = 10)\n#&gt;  [1] 1 2 4 1 2 4 1 2 4 1\n\ntimes and length.out replicate the vector in the same way, but length.out allows you to specify a non-integer number of replications. If you specify both, length.out wins.\n\nrep(x, times = 3, length.out = 10)\n#&gt;  [1] 1 2 4 1 2 4 1 2 4 1\n\nThe each argument repeats individual components of the vector rather than the whole vector:\n\nrep(x, each = 3)\n#&gt; [1] 1 1 1 2 2 2 4 4 4\n\nAnd you can combine that with times:\n\nrep(x, each = 3, times = 2)\n#&gt;  [1] 1 1 1 2 2 2 4 4 4 1 1 1 2 2 2 4 4 4\n\nIf you supply a vector to times it works a similar way to each, repeating each component the specified number of times:\n\nrep(x, times = x)\n#&gt; [1] 1 2 2 4 4 4 4"
  },
  {
    "objectID": "cs-rep.html#what-makes-this-function-hard-to-understand",
    "href": "cs-rep.html#what-makes-this-function-hard-to-understand",
    "title": "12  Case study: rep()",
    "section": "\n12.2 What makes this function hard to understand?",
    "text": "12.2 What makes this function hard to understand?\n\n\nThere’s a complicated dependency between times, length.out, and each. times and length.out both control the same underlying variable in different ways, and you can not set them simultaneously. times and each are mostly independent, but if you specify a vector for times you can’t use each.\n\nrep(1:3, times = c(2, 2, 2), each = 2)\n#&gt; Error in rep(1:3, times = c(2, 2, 2), each = 2): invalid 'times' argument\n\n\n\nI think using times with a vector is confusing because it switches from replicating the whole vector to replicating individual values of the vector, like each usually does.\n\nrep(1:3, each = 2)\n#&gt; [1] 1 1 2 2 3 3\nrep(1:3, times = 2)\n#&gt; [1] 1 2 3 1 2 3\nrep(1:3, times = c(2, 2, 2))\n#&gt; [1] 1 1 2 2 3 3\n\n\n\nI think these two problems have the same underlying cause: rep() is trying to do too much in a single function. I think we can make things simpler by turning rep() into two functions: one that replicates the full vector, and one that replicates each element of the vector."
  },
  {
    "objectID": "cs-rep.html#how-might-we-improve-the-situation",
    "href": "cs-rep.html#how-might-we-improve-the-situation",
    "title": "12  Case study: rep()",
    "section": "\n12.3 How might we improve the situation?",
    "text": "12.3 How might we improve the situation?\nTwo create two new functions, we need to first come up with names: I like rep_each() and rep_full(). rep_each() was a fairly easy name to come up with. rep_full() was a little harder and took a few iterations: I like that full has the same number of letters as each, which makes the two functions look like they belong together.\nNext, we need to think about their arguments. Both will have a single data argument: x, the vector to replicate. rep_each() has a single details argument which specifies the number of times to replicate each element. rep_time() has two mutually exclusive details arguments, the number of times to repeat the whole vector, or the desired length of the output.\nWhat should we call the arguments? We’ve already captured the different replication strategies (each vs. full) in the function name, so I think the argument that specifies the number of times to replicate can be the same, and times seems reasonable. For the second argument to rep_full(), I draw inspiration from rep() which uses length.out. I think it’s obvious that the argument controls the output, so length is adequate.\n\nrep_each &lt;- function(x, times) {\n  times &lt;- rep(times, length.out = length(x))\n  rep(x, times = times)\n}\n\nrep_full &lt;- function(x, times, length) {\n  rlang::check_exclusive(times, length)\n  \n  if (!missing(length)) {\n    rep(x, length.out = length)\n  } else {\n    rep(x, length.out = times * base::length(x))\n  }\n}\n\n(Note the downside of using length as the argument name: we have to call base::length() to avoid evaluating the missing length when times is supplied.)\n\nx &lt;- c(1, 2, 4)\n\nrep_each(x, times = 2)\n#&gt; [1] 1 1 2 2 4 4\nrep_full(x, times = 2)\n#&gt; [1] 1 2 4 1 2 4\n\nrep_each(x, times = x)\n#&gt; [1] 1 2 2 4 4 4 4\n\nrep_full(x, length = 5)\n#&gt; [1] 1 2 4 1 2\n\nOne downside of this approach is if you want to both replicate each component and the entire vector, you have to use two function calls, which is much more verbose than the rep() equivalent. However, I don’t think this is a terribly common use case, and so I think a longer call is more readable."
  },
  {
    "objectID": "cs-rep.html#dealing-with-bad-inputs",
    "href": "cs-rep.html#dealing-with-bad-inputs",
    "title": "12  Case study: rep()",
    "section": "\n12.4 Dealing with bad inputs",
    "text": "12.4 Dealing with bad inputs\nThe implementations above work well for correct inputs, but will also work without error for a number of incorrect inputs:\n\nrep_full(1:3, 1:3)\n#&gt; Warning in rep(x, length.out = times * base::length(x)): first element used of\n#&gt; 'length.out' argument\n#&gt; [1] 1 2 3\n\nNeed to think about the types\n\nrep_each &lt;- function(x, times) {\n  times &lt;- vctrs::vec_cast(times, integer())\n  times &lt;- vctrs::vec_recycle(times, vctrs::vec_size(x), x_arg = \"times\")\n  \n  rep.int(x, times)\n}\n\nrep_full &lt;- function(x, times, length) {\n  rlang::check_exclusive(times, length)\n  \n  if (!missing(length)) {\n    rlang:::check_number_whole(length)\n    rep(x, length.out = length)\n  } else {\n    rlang:::check_number_decimal(times)\n    rep(x, length.out = times * base::length(x))\n  }\n}\n\n\nrep_each(1:3, 1:2)\n#&gt; Error in `rep_each()`:\n#&gt; ! Can't recycle `times` (size 2) to size 3.\nrep_each(1:3, \"x\")\n#&gt; Error in `rep_each()`:\n#&gt; ! Can't convert `times` &lt;character&gt; to &lt;integer&gt;.\n\nrep_full(1:3, \"x\")\n#&gt; Error in `rep_full()`:\n#&gt; ! `times` must be a number, not the string \"x\".\nrep_full(1:3, c(1, 2))\n#&gt; Error in `rep_full()`:\n#&gt; ! `times` must be a number, not a double vector."
  },
  {
    "objectID": "cs-rep.html#footnotes",
    "href": "cs-rep.html#footnotes",
    "title": "12  Case study: rep()",
    "section": "",
    "text": "Note that the function specification is rep(x, ...), and times, each, and length.out do not appear explicitly. You have to read the documentation to discover these arguments.↩︎"
  },
  {
    "objectID": "def-magical.html#whats-the-problem",
    "href": "def-magical.html#whats-the-problem",
    "title": "13  Avoid magical defaults",
    "section": "\n13.1 What’s the problem?",
    "text": "13.1 What’s the problem?\nIf a function behaves differently when the default value is supplied explicitly, we say it has a magical default. Magical defaults are best avoided because they make it harder to interpret the function specification."
  },
  {
    "objectID": "def-magical.html#what-are-some-examples",
    "href": "def-magical.html#what-are-some-examples",
    "title": "13  Avoid magical defaults",
    "section": "\n13.2 What are some examples?",
    "text": "13.2 What are some examples?\n\n\nIn data.frame(), the default argument for row.names is NULL, but if you supply it directly you get a different result:\n\nargs(data.frame)\n#&gt; function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE, \n#&gt;     fix.empty.names = TRUE, stringsAsFactors = FALSE) \n#&gt; NULL\n\nx &lt;- setNames(nm = letters[1:2])\nx\n#&gt;   a   b \n#&gt; \"a\" \"b\"\n\ndata.frame(x)\n#&gt;   x\n#&gt; a a\n#&gt; b b\n\ndata.frame(x, row.names = NULL)\n#&gt;   x\n#&gt; 1 a\n#&gt; 2 b\n\n\n\nIn hist(), the default value of xlim is range(breaks), and the default value for breaks is \"Sturges\". range(\"Sturges\") returns c(\"Sturges\", \"Sturges\") which doesn’t work when supplied explicitly:\n\nargs(hist.default)\n#&gt; function (x, breaks = \"Sturges\", freq = NULL, probability = !freq, \n#&gt;     include.lowest = TRUE, right = TRUE, fuzz = 1e-07, density = NULL, \n#&gt;     angle = 45, col = \"lightgray\", border = NULL, main = paste(\"Histogram of\", \n#&gt;         xname), xlim = range(breaks), ylim = NULL, xlab = xname, \n#&gt;     ylab, axes = TRUE, plot = TRUE, labels = FALSE, nclass = NULL, \n#&gt;     warn.unused = TRUE, ...) \n#&gt; NULL\n\nhist(1:10, xlim = c(\"Sturges\", \"Sturges\"))\n#&gt; Error in plot.window(xlim, ylim, \"\", ...): invalid 'xlim' value\n\n\n\nreadr::read_csv() has progress = show_progress(), but until version 1.3.1, show_progress() was not exported from the package. That means if you attempted to run it yourself, you’d see an error message:\n\nshow_progress()\n#&gt; Error in show_progress(): could not find function \"show_progress\""
  },
  {
    "objectID": "def-magical.html#what-are-the-exceptions",
    "href": "def-magical.html#what-are-the-exceptions",
    "title": "13  Avoid magical defaults",
    "section": "\n13.3 What are the exceptions?",
    "text": "13.3 What are the exceptions?\nIt’s ok to use this behaviour when you want the default value of one argument to be the same as another. For example, take rlang::set_names(), which allows you to create a named vector from two inputs:\n\nlibrary(rlang)\nargs(set_names)\n#&gt; function (x, nm = x, ...) \n#&gt; NULL\n\nset_names(1:3, letters[1:3])\n#&gt; a b c \n#&gt; 1 2 3\n\nThe default value for the names is the vector itself. This provides a convenient shortcut for naming a vector with itself:\n\nset_names(letters[1:3])\n#&gt;   a   b   c \n#&gt; \"a\" \"b\" \"c\"\n\nYou can see this same technique in merge(), where all.x and all.y default to the same value as all, and in factor() where labels defaults to the same value as levels.\nIf you use this technique, make sure that you never use the value of an argument that comes later in the argument list. For example, in file.copy() overwrite defaults to the same value as recursive, but the recursive argument is defined after overwrite:\n\nargs(file.copy)\n#&gt; function (from, to, overwrite = recursive, recursive = FALSE, \n#&gt;     copy.mode = TRUE, copy.date = FALSE) \n#&gt; NULL\n\nThis makes the defaults arguments harder to understand because you can’t just read from left-to-right."
  },
  {
    "objectID": "def-magical.html#what-causes-the-problem",
    "href": "def-magical.html#what-causes-the-problem",
    "title": "13  Avoid magical defaults",
    "section": "\n13.4 What causes the problem?",
    "text": "13.4 What causes the problem?\nThis problem is generally easy to avoid for new functions:\n\n\nDon’t use default values that depend on variables defined inside the function. The default values of function arguments are lazily evaluated in the environment of the function when they are first used, as described in Advanced R. Here’s a simple example:\n\nf1 &lt;- function(x = y) {\n  y &lt;- 2\n  x\n}\n\ny &lt;- 1\nf1()\n#&gt; [1] 2\nf1(y)\n#&gt; [1] 1\n\nWhen x takes the value y from its default, it’s evaluated inside the function, yielding 1. When y is supplied explicitly, it is evaluated in the caller environment, yielding 2.\n\n\nDon’t use missing()[^def-magical-1].\n\nf2 &lt;- function(x = 1) {\n  if (missing(x)) {\n    2\n  } else {\n    x\n  }\n}\n\nf2()\n#&gt; [1] 2\nf2(1)\n#&gt; [1] 1\n\n\nDon’t use unexported functions. In packages, it’s easy to use a non-exported function without thinking about it. This function is available to you, the package author, but not the user of the package, which makes it harder for them to understand how a package works."
  },
  {
    "objectID": "def-magical.html#how-do-i-remediate-the-problem",
    "href": "def-magical.html#how-do-i-remediate-the-problem",
    "title": "13  Avoid magical defaults",
    "section": "\n13.5 How do I remediate the problem?",
    "text": "13.5 How do I remediate the problem?\nIf you have a made a mistake in an older function you can remediate it by using a NULL default, as described in Chapter 9). If the problem is caused by an unexported function, you can also choose to document and export it. Remediating this problem shouldn’t break existing code, because it expands the function interface: all previous code will continue to work, and the function will also work if the argument is passed NULL input (which probably didn’t previously).\nFor functions like data.frame() where NULL is already a permissible value, you’ll need to use a sentinel object, as described in Section 9.3.3.\n\nsentinel &lt;- function() structure(list(), class = \"sentinel\")\nis_sentinel &lt;- function(x) inherits(x, \"sentinel\")\n\ndata.frame_better &lt;- function(..., row.names = sentinel()) {\n  if (is_sentinel(row.names)) {\n    # old default behaviour\n  }\n}"
  },
  {
    "objectID": "def-inform.html#whats-the-pattern",
    "href": "def-inform.html#whats-the-pattern",
    "title": "14  Explain important defaults",
    "section": "\n14.1 What’s the pattern?",
    "text": "14.1 What’s the pattern?\nIf a default value is important, and the computation is non-trivial, inform the user what value was used. This is particularly important when the default value is an educated guess, and you want the user to change it. It is also important when descriptor arguments (Chapter 6)) have defaults."
  },
  {
    "objectID": "def-inform.html#what-are-some-examples",
    "href": "def-inform.html#what-are-some-examples",
    "title": "14  Explain important defaults",
    "section": "\n14.2 What are some examples?",
    "text": "14.2 What are some examples?\n\n\ndplyr::left_join() and friends automatically compute the variables to join by as the variables that occur in both x and y (this is called a natural join in SQL). This is convenient, but it’s a heuristic so doesn’t always work.\n\nlibrary(nycflights13)\nlibrary(dplyr)\n\n# Correct    \nout &lt;- left_join(flights, airlines)\n#&gt; Joining with `by = join_by(carrier)`\n\n# Incorrect\nout &lt;- left_join(flights, planes)\n#&gt; Joining with `by = join_by(year, tailnum)`\n\n# Error\nout &lt;- left_join(flights, airports)\n#&gt; Error in `left_join()`:\n#&gt; ! `by` must be supplied when `x` and `y` have no common variables.\n#&gt; ℹ Use `cross_join()` to perform a cross-join.\n\n\n\nreadr::read_csv() reads a csv file into a data frame. Because csv files don’t store the type of each variable, readr must guess the types. In order to be fast, read_csv() uses some heuristics, so it might guess wrong. Or maybe guesses correctly today, but when your automated script runs in two months time when the data format has changed, it might guess incorrectly and give weird downstream errors. For this reason, read_csv() prints the column specification in a way that you can copy-and-paste into your code.\n\nlibrary(readr)\nmtcars &lt;- read_csv(readr_example(\"mtcars.csv\"))\n#&gt; Rows: 32 Columns: 11\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nIn ggplot2::geom_histogram(), the binwidth is an important parameter that you should always experiment with. This suggests it should be a required argument, but it’s hard to know what values to try until you’ve seen a plot. For this reason, ggplot2 provides a suboptimal default of 30 bins: this gets you started, and then a message tells you how to modify.\n\nlibrary(ggplot2)\nggplot(diamonds, aes(carat)) + geom_histogram()\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nWhen installing packages, install.packages() informs of the value of the lib argument, which defaults to .libPath()[[1]]:\n\ninstall.packages(\"forcats\")\n# Installing package into ‘/Users/hadley/R’\n# (as ‘lib’ is unspecified)\n\nThis, however, is not terribly important (most people only use one library), it’s easy to ignore this amongst the other output, and the message doesn’t refer to the mechanism that controls the default (.libPaths())."
  },
  {
    "objectID": "def-inform.html#why-is-it-important",
    "href": "def-inform.html#why-is-it-important",
    "title": "14  Explain important defaults",
    "section": "\n14.3 Why is it important?",
    "text": "14.3 Why is it important?\n\nThere are two ways to fire a machine gun in the dark. You can find out exactly where your target is (range, elevation, and azimuth). You can determine the environmental conditions (temperature, humidity, air pressure, wind, and so on). You can determine the precise specifications of the cartridges and bullets you are using, and their interactions with the actual gun you are firing. You can then use tables or a firing computer to calculate the exact bearing and elevation of the barrel. If everything works exactly as specified, your tables are correct, and the environment doesn’t change, your bullets should land close to their target.\nOr you could use tracer bullets.\nTracer bullets are loaded at intervals on the ammo belt alongside regular ammunition. When they’re fired, their phosphorus ignites and leaves a pyrotechnic trail from the gun to whatever they hit. If the tracers are hitting the target, then so are the regular bullets.\n— The Pragmatic Programmer\n\nI think this is a valuable pattern because it helps balance two tensions in function design:\n\nForcing the function user to really think about what they want to do.\nTrying to be helpful, so the user of function can achieve their goal as quickly as possible.\n\nOften your thoughts about a problem will be aided by a first attempt, even if that attempt is wrong. Helps facilitate iteration: you don’t sit down and contemplate for an hour and then write one perfectly formed line of R code. You take a stab at it, look at the result, and then tweak.\nTaking a default that the user really should carefully think about and make a decision on, and turning it into a heurstic or educated guess, and reporting the value, is like a tracer bullet.\nThe counterpoint to this pattern is that people don’t read repeated output. For example, do you know how to cite R in a paper? It’s mentioned every time that you start R. Human brains are extremely good at filtering out unchanging signals, which means that you must use this technique with caution. If every argument tells you the default it uses, it’s effectively the same as doing nothing: the most important signals will get buried in the noise. This is why you’ll see the technique used in only a handful of places in the tidyverse."
  },
  {
    "objectID": "def-inform.html#how-can-i-use-it",
    "href": "def-inform.html#how-can-i-use-it",
    "title": "14  Explain important defaults",
    "section": "\n14.4 How can I use it?",
    "text": "14.4 How can I use it?\nTo use this message you need to generate a message from the computation of the default value. The easiest way to do this to write a small helper function. It should compute the default value given some inputs and generate a message() that gives the code that you could copy and paste into the function call.\nTake the dplyr join functions, for example. They use a function like this:\n\ncommon_by &lt;- function(x, y) {\n  common &lt;- intersect(names(x), names(y))\n  if (length(common) == 0) {\n    stop(\"Must specify `by` when no common variables in `x` and `y`\", call. = FALSE)\n  }\n  \n  message(\"Computing common variables: `by = \", rlang::expr_text(common), \"`\")\n  common\n}\n\ncommon_by(data.frame(x = 1), data.frame(x = 1))\n#&gt; Computing common variables: `by = \"x\"`\n#&gt; [1] \"x\"\ncommon_by(flights, planes)\n#&gt; Computing common variables: `by = c(\"year\", \"tailnum\")`\n#&gt; [1] \"year\"    \"tailnum\"\n\nThe technique you use to generate the code will vary from function to function. rlang::expr_text() is useful here because it automatically creates the code you’d use to build the character vector.\nTo avoid creating a magical default (Chapter 13), either export and document the function, or use the technique of Section 9.3.1:\n\nleft_join &lt;- function(x, y, by = NULL) {\n  by &lt;- by %||% common_by(x, y)\n}"
  },
  {
    "objectID": "def-user.html#whats-the-pattern",
    "href": "def-user.html#whats-the-pattern",
    "title": "15  User settable defaults",
    "section": "\n15.1 What’s the pattern?",
    "text": "15.1 What’s the pattern?\nIt’s sometimes useful to give the user control over default values, so that they can set once per session or once for every session in their .Rprofile. To do so, use getOption() in the default value.\nNote that this pattern should general only be used to control the side-effects of a function, not its compute value. The two primary uses are for controlling the appearance of output, particularly in print() methods, and for setting default values in generated templates.\nRelated patterns:\n\nIf a global option affects the results of the computation (not just its side-effects), you have an example of Chapter 5."
  },
  {
    "objectID": "def-user.html#what-are-some-examples",
    "href": "def-user.html#what-are-some-examples",
    "title": "15  User settable defaults",
    "section": "\n15.2 What are some examples?",
    "text": "15.2 What are some examples?"
  },
  {
    "objectID": "def-user.html#why-is-it-important",
    "href": "def-user.html#why-is-it-important",
    "title": "15  User settable defaults",
    "section": "\n15.3 Why is it important?",
    "text": "15.3 Why is it important?"
  },
  {
    "objectID": "def-user.html#what-are-the-exceptions",
    "href": "def-user.html#what-are-the-exceptions",
    "title": "15  User settable defaults",
    "section": "\n15.4 What are the exceptions?",
    "text": "15.4 What are the exceptions?"
  },
  {
    "objectID": "def-user.html#how-do-i-use-it",
    "href": "def-user.html#how-do-i-use-it",
    "title": "15  User settable defaults",
    "section": "\n15.5 How do I use it?",
    "text": "15.5 How do I use it?"
  },
  {
    "objectID": "cs-rgb.html",
    "href": "cs-rgb.html",
    "title": "16  Case study: rgb()",
    "section": "",
    "text": "Interface:\n\nFunction name and argument names.\n\nalpha has no default but isn’t required.\n\nnames not required (imo).\n\nmaxColorValue doens’t have most useful default, and not really needed (imo).\nData frame rather than matrix.\nError if function specification is correct\nCheck for data type, not missingness.\n\n\nlibrary(rlang)\n\nrgba &lt;- function(r, g, b, a = NULL) {\n  if (is.data.frame(r)) {\n    df &lt;- r\n    if (!ncol(df) %in% c(3L, 4L)) {\n      abort(\"If `r` is data frame, it must have 3 or 4 columns.\")\n    }\n    \n    if (!missing(b) || !missing(g) || !missing(a)) {\n      abort(\"If `r` is a data frame, `b`, `g`, and `a` must not be set.\")\n    }\n    \n    r &lt;- df[[1L]]\n    g &lt;- df[[2L]]\n    b &lt;- df[[3L]]\n    if (ncol(df) == 4) {\n      a &lt;- df[[4L]]\n    }\n  }\n  \n  rgb(r, g, b, alpha = a, maxColorValue = 255)\n}\n\nrgba(16, 16, 16)\n#&gt; [1] \"#101010\"\nrgba(data.frame(16, 16, 16))\n#&gt; [1] \"#101010\"\nrgba(data.frame(16, 16))\n#&gt; Error in `rgba()`:\n#&gt; ! If `r` is data frame, it must have 3 or 4 columns.\nrgba(data.frame(16, 16, 16), 1)\n#&gt; Error in `rgba()`:\n#&gt; ! If `r` is a data frame, `b`, `g`, and `a` must not be set.\n\n\nrgba &lt;- function(r, g, b, a = NULL) {\n  if (is.data.frame(r)) {\n    df &lt;- r\n    if (!all(c(\"r\", \"g\", \"b\")) %in% names(df)) {\n      abort(\"If first argument is a data frame, it must have r, g, and b columns.\")\n    }\n    \n    if (!missing(b) || !missing(g) || !missing(a)) {\n      abort(\"If `r` is a data frame, `b`, `g`, and `a` must not be set.\")\n    }\n  } else {\n    # Handles vectorisation\n    df &lt;- tibble(r = r, g = g, b = b, a = a) \n  }\n  \n  # Assumes this function checks types and gives informative error messages\n  rgb(df$r, df$g, df$b, alpha = df$a, maxColorValue = 255)\n}"
  },
  {
    "objectID": "dots-data.html#whats-the-problem",
    "href": "dots-data.html#whats-the-problem",
    "title": "17  Making data with …",
    "section": "\n17.1 What’s the problem?",
    "text": "17.1 What’s the problem?\nA number of functions take ... to save the user from having to create a vector themselves:"
  },
  {
    "objectID": "dots-data.html#what-are-some-examples",
    "href": "dots-data.html#what-are-some-examples",
    "title": "17  Making data with …",
    "section": "\n17.2 What are some examples?",
    "text": "17.2 What are some examples?\n\nsum(c(1, 1, 1))\n#&gt; [1] 3\n# can be shortened to:\nsum(1, 1, 1)\n#&gt; [1] 3\n\nf &lt;- factor(c(\"a\", \"b\", \"c\", \"d\"), levels = c(\"b\", \"c\", \"d\", \"a\"))\nf\n#&gt; [1] a b c d\n#&gt; Levels: b c d a\nfct_relevel(f, c(\"b\", \"a\"))\n#&gt; [1] a b c d\n#&gt; Levels: b a c d\n# can be shortened to:\nfct_relevel(f, \"b\", \"a\")\n#&gt; [1] a b c d\n#&gt; Levels: b a c d\n\n\nmapply()"
  },
  {
    "objectID": "dots-data.html#why-is-it-important",
    "href": "dots-data.html#why-is-it-important",
    "title": "17  Making data with …",
    "section": "\n17.3 Why is it important?",
    "text": "17.3 Why is it important?\nIn general, I think it is best to avoid using ... for this purpose because it has a relatively small benefit, only reducing typing by three letters c(), but has a number of costs:\n\n\nIt can give the misleading impression that other functions in the same family work the same way. For example, if you’re internalised how sum() works, you might predict that mean() works the same way, but it does not:\n\nmean(c(1, 2, 3))\n#&gt; [1] 2\nmean(1, 2, 3)\n#&gt; [1] 1\n\n(See Chapter Chapter 8 to learn why this doesn’t give an error message.)\n\n\nIt makes it harder to adapt the function for new uses. For example, fct_relevel() can also be called with a function:\n\nfct_relevel(f, sort)\n#&gt; [1] a b c d\n#&gt; Levels: a b c d\n\nIf fct_relevel() took its input as a single vector, you could easily extend it to also work with functions:\n\nfct_relevel &lt;- function(f, x) {\n  if (is.function(x)) {\n    x &lt;- f(levels(x))\n  }\n}\n\nHowever, because fct_relevel() uses dots, the implementation needs to be more complicated:\n\nfct_relevel &lt;- function(f, ...) {\n  if (dots_n(...) == 1L && is.function(..1)) {\n    levels &lt;- fun(levels(x))\n  } else {\n    levels &lt;- c(...)\n  }\n}"
  },
  {
    "objectID": "dots-data.html#what-are-the-exceptions",
    "href": "dots-data.html#what-are-the-exceptions",
    "title": "17  Making data with …",
    "section": "\n17.4 What are the exceptions?",
    "text": "17.4 What are the exceptions?\nNote that in all the examples above, the ... are used to collect a single details argument. It’s ok to use ... to collect data, as in paste(), data.frame(), or list()."
  },
  {
    "objectID": "dots-data.html#how-can-remediate-it",
    "href": "dots-data.html#how-can-remediate-it",
    "title": "17  Making data with …",
    "section": "\n17.5 How can remediate it?",
    "text": "17.5 How can remediate it?\nIf you’ve already published a function where you’ve used ... for this purpose you can change the interface by adding a new argument in front of ..., and then warning if anything ends up in ....\n\nold_foo &lt;- function(x, ...) {\n}\n\nnew_foo &lt;- function(x, y, ...) {\n  if (rlang::dots_n(...) &gt; 0) {\n    warning(\"Use of `...` is now deprecated. Please put all arguments in `y`\")\n    y &lt;- c(y, ...)\n  }\n}\n\nBecause this is a interface change, it should be prominently advertised in packages."
  },
  {
    "objectID": "dots-data.html#how-can-i-protect-myself",
    "href": "dots-data.html#how-can-i-protect-myself",
    "title": "17  Making data with …",
    "section": "\n17.6 How can I protect myself?",
    "text": "17.6 How can I protect myself?\nIf you do feel that the tradeoff is worth it (i.e. it’s an extremely frequently used function and the savings over time will be considerable), you need to take some steps to minimise the downsides.\nThis is easiest if you’re constructing a vector that shouldn’t have names. In this case, you can call rlang::check_dots_unnamed() to ensure that no named arguments have been accidentally passed to .... This protects you against the following undesirable behaviour of sum():\n\nsum(1, 1, 1, na.omit = TRUE)\n#&gt; [1] 4\n\nsafe_sum &lt;- function(..., na.rm = TRUE) {\n  rlang::check_dots_unnamed()\n  sum(c(...), na.rm = na.rm)\n}\nsafe_sum(1, 1, 1, na.omit = TRUE)\n#&gt; Error in `safe_sum()`:\n#&gt; ! Arguments in `...` must be passed by position, not name.\n#&gt; ✖ Problematic argument:\n#&gt; • na.omit = TRUE\n\nIf you want your vector to have names, the problem is harder, and there’s relatively little that you can. You’ll need to ensure that all other arguments get a . prefix (to minimise chances of a mismatch) and then think carefully about how you might detect problems by thinking about the expect type of c(...). As far as I know, there are no general techniques, and you’ll have to think about the problem on a case-by-case basis."
  },
  {
    "objectID": "dots-data.html#selecting-variables",
    "href": "dots-data.html#selecting-variables",
    "title": "17  Making data with …",
    "section": "\n17.7 Selecting variables",
    "text": "17.7 Selecting variables\nA number of funtions in the tidyverse use ... for selecting variables. For example, tidyr::fill() lets you fill in missing values based on the previous row:\n\ndf &lt;- tribble(\n  ~year,  ~month, ~day,\n  2020,  1,       1,\n  NA,    NA,      2,\n  NA,    NA,      3,\n  NA,    2,       1\n)\ndf %&gt;% fill(year, month)\n#&gt; # A tibble: 4 × 3\n#&gt;    year month   day\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2020     1     1\n#&gt; 2  2020     1     2\n#&gt; 3  2020     1     3\n#&gt; 4  2020     2     1\n\nAll functions that work like this include a call to tidyselect::vars_select() that looks something like this:\n\nfind_vars &lt;- function(data, ...) {\n  tidyselect::vars_select(names(data), ...)\n}\n\nfind_vars(df, year, month)\n#&gt;    year   month \n#&gt;  \"year\" \"month\"\n\nI now think that this interface is a mistake because it suffers from the same problem as sum(): we’re using ... to only save a little typing. We can eliminate the use of dots by requiring the user to use c(). (This change also requires explicit quoting and unquoting of vars since we’re no longer using ....)\n\nfoo &lt;- function(data, vars) {\n  tidyselect::vars_select(names(data), !!enquo(vars))\n}\n\nfind_vars(df, c(year, month))\n#&gt;    year   month \n#&gt;  \"year\" \"month\"\n\nIn other words, I believe that better interface to fill() would be:\n\ndf %&gt;% fill(c(year, month))\n\nOther tidyverse functions like dplyr’s scoped verbs and ggplot2::facet_grid() require the user to explicitly quote the input. I now believe that this is also a suboptimal interface because it is more typing (var() is longer than c(), and you must quote even single variables), and arguments that require their inputs to be explicitly quoted are rare in the tidyverse.\n\n# existing interface\ndplyr::mutate_at(mtcars, vars(cyl:vs), mean)\n# what I would create today\ndplyr::mutate_at(mtcars, c(cyl:vs), mean)\n\n# existing interface\nggplot2::facet_grid(rows = vars(drv), cols = vars(vs, am))\n# what I would create today\nggplot2::facet_grid(rows = drv, cols = c(vs, am))\n\nThat said, it is unlikely we will ever change functions, because the benefit is smaller (primarily improved consistency) and the costs are high, as it impossible to switch from an evaluated argument to a quoted argument without breaking backward compatibility in some small percentage of cases."
  },
  {
    "objectID": "dots-prefix.html#whats-the-pattern",
    "href": "dots-prefix.html#whats-the-pattern",
    "title": "18  Dot prefix",
    "section": "\n18.1 What’s the pattern?",
    "text": "18.1 What’s the pattern?\nWhen using ... to create a data structure, or when passing ... to a user-supplied function, add a . prefix to all named arguments. This reduces (but does not eliminate) the chances of matching an argument at the wrong level. Additionally, you should always provide some mechanism that allows you to escape and use that name if needed.\n\nlibrary(purrr)\n\n(Not important if you ignore names: e.g. cat().)"
  },
  {
    "objectID": "dots-prefix.html#what-are-some-examples",
    "href": "dots-prefix.html#what-are-some-examples",
    "title": "18  Dot prefix",
    "section": "\n18.2 What are some examples?",
    "text": "18.2 What are some examples?\nLook at the arguments to some functions in purrr:\n\nargs(map)\n#&gt; function (.x, .f, ..., .progress = FALSE) \n#&gt; NULL\nargs(reduce)\n#&gt; function (.x, .f, ..., .init, .dir = c(\"forward\", \"backward\")) \n#&gt; NULL\nargs(detect)\n#&gt; function (.x, .f, ..., .dir = c(\"forward\", \"backward\"), .right = NULL, \n#&gt;     .default = NULL) \n#&gt; NULL\n\nNotice that all named arguments start with .. This reduces the chance that you will incorrectly match an argument to map(), rather than to an argument of .f. Obviously it can’t eliminate it.\nEscape mechanism is the anonymous function. Little easier to access in purrr::map() since you can create with ~, which is much less typing than function() {}. For example, imagine you want to…\nExample: https://jennybc.github.io/purrr-tutorial/ls02_map-extraction-advanced.html#list_inside_a_data_frame"
  },
  {
    "objectID": "dots-prefix.html#case-study-dplyr-verbs",
    "href": "dots-prefix.html#case-study-dplyr-verbs",
    "title": "18  Dot prefix",
    "section": "\n18.3 Case study: dplyr verbs",
    "text": "18.3 Case study: dplyr verbs\n\nargs(dplyr::filter)\n#&gt; function (.data, ..., .by = NULL, .preserve = FALSE) \n#&gt; NULL\nargs(dplyr::group_by)\n#&gt; function (.data, ..., .add = FALSE, .drop = group_by_drop_default(.data)) \n#&gt; NULL\n\nEscape hatch is :=.\nOoops:\n\nargs(dplyr::left_join)\n#&gt; function (x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), \n#&gt;     ..., keep = NULL) \n#&gt; NULL"
  },
  {
    "objectID": "dots-prefix.html#other-approaches-in-base-r",
    "href": "dots-prefix.html#other-approaches-in-base-r",
    "title": "18  Dot prefix",
    "section": "\n18.4 Other approaches in base R",
    "text": "18.4 Other approaches in base R\nBase R uses two alternative methods: uppercase and _ prefix.\nThe apply family tends to use uppercase function names for the same reason. Unfortunately the functions are a little inconsistent which makes it hard to see this pattern. I think a dot prefix is better because it’s easier to type (you don’t have to hold down the shift-key with one finger).\n\nargs(lapply)\n#&gt; function (X, FUN, ...) \n#&gt; NULL\nargs(sapply)\n#&gt; function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE) \n#&gt; NULL\nargs(apply)\n#&gt; function (X, MARGIN, FUN, ..., simplify = TRUE) \n#&gt; NULL\nargs(mapply)\n#&gt; function (FUN, ..., MoreArgs = NULL, SIMPLIFY = TRUE, USE.NAMES = TRUE) \n#&gt; NULL\nargs(tapply)\n#&gt; function (X, INDEX, FUN = NULL, ..., default = NA, simplify = TRUE) \n#&gt; NULL\n\nReduce() and friends avoid the problem altogether by not accepting ..., and requiring that the user creates anonymous functions. But this is verbose, particularly without shortcuts to create functions.\ntransform() goes a step further and uses an non-syntactic variable name.\n\nargs(transform)\n#&gt; function (`_data`, ...) \n#&gt; NULL\n\nUsing a non-syntactic variable names means that it must always be surrounded in `. This means that a user is even less likely to use it that with ., but it increases friction when writing the function. In my opinion, this trade-off is not worth it."
  },
  {
    "objectID": "dots-prefix.html#what-are-the-exceptions",
    "href": "dots-prefix.html#what-are-the-exceptions",
    "title": "18  Dot prefix",
    "section": "\n18.5 What are the exceptions?",
    "text": "18.5 What are the exceptions?\n\n\ntryCatch(): the names give classes so, as long as you don’t create a condition class called expr or finally (which would be weird!) you don’t need to worry about matches."
  },
  {
    "objectID": "dots-inspect.html#whats-the-pattern",
    "href": "dots-inspect.html#whats-the-pattern",
    "title": "19  Inspect the dots",
    "section": "\n19.1 What’s the pattern?",
    "text": "19.1 What’s the pattern?\nWhenever you use ... in an S3 generic to allow methods to add custom arguments, you should inspect the dots to make sure that every argument is used. You can also use this same approach when passing ... to an overly permissive function."
  },
  {
    "objectID": "dots-inspect.html#what-are-some-examples",
    "href": "dots-inspect.html#what-are-some-examples",
    "title": "19  Inspect the dots",
    "section": "\n19.2 What are some examples?",
    "text": "19.2 What are some examples?\nIf you don’t use this technique it is easy to end up with functions that silently return the incorrect result when argument names are misspelled.\n\n# Misspelled\nweighted.mean(c(1, 0, -1), wt = c(10, 0, 0))\n#&gt; [1] 0\nmean(c(1:9, 100), trim = 0.1)\n#&gt; [1] 5.5\n\n# Correct\nweighted.mean(c(1, 0, -1), w = c(10, 0, 0))\n#&gt; [1] 1\nmean(c(1:9, 100), trim = 0.1)\n#&gt; [1] 5.5"
  },
  {
    "objectID": "dots-inspect.html#how-do-i-do-it",
    "href": "dots-inspect.html#how-do-i-do-it",
    "title": "19  Inspect the dots",
    "section": "\n19.3 How do I do it?",
    "text": "19.3 How do I do it?\nAdd a call to rlang::check_dots_used() in the generic before the call to UseMethod(). This automatically adds an on exit handler, which checks that ever element of ... has been evaluated just prior to the function returnning.\nYou can see this in action by creating a safe wrapper around cut(), which has different arguments for its numeric and date methods.\n\nsafe_cut &lt;- function(x, breaks, ..., right = TRUE) {\n  rlang::check_dots_used()\n  UseMethod(\"safe_cut\")\n}\n\nsafe_cut.numeric &lt;- function(x, breaks, ..., right = TRUE, include.lowest = FALSE) {\n  cut(x, breaks = breaks, right = right, include.lowest = include.lowest)\n}\n\nsafe_cut.Date &lt;- function(x, breaks, ..., right = TRUE, start.on.monday = TRUE) {\n  cut(x, breaks = breaks, right = right, start.on.monday = start.on.monday)\n}\n\n\n19.3.1 What are the limitations?\nAccurately detecting this problem is hard because no one place has all the information needed to tell if an argument is superfluous or not (the precise details are beyond the scope of this text). Instead rlang takes advantage of R’s lazy evaluation and inspects the internal components of ... to see if their evaluation has been forced.\nIf a function is called primarily for its side-effects, the error will occur after the side-effect has happened, making for a confusing result. Here the best we can do is a warning, generated by rlang::check_dots_used(error = function(e) warn(e))\nIf a function captures the components of ... using enquo() or match.call(), you can not use this technique. This also means that if you use check_dots_used(), the method author can not choose to add a quoted argument. I think this is ok because quoting vs. evaluating is part of the interface of the generic, so methods should not change this interface, and it’s fine for the author of the generic to make that decision for all method authors.\n\n19.3.2 What are other uses?\nThis same technique can also be used when you are wrapping other functions. For example, stringr::str_sort() takes ... and passes it on to stringi::stri_opts_collator(). As of March 2019, str_sort() looked like this:\n\nstr_sort &lt;- function(x, decreasing = FALSE, na_last = TRUE, locale = \"en\",  numeric = FALSE, ...) \n{\n    stringi::stri_sort(x, \n      decreasing = decreasing, \n      na_last = na_last, \n      opts_collator = stringi::stri_opts_collator(\n        locale, \n        numeric = numeric, \n        ...\n      )\n    )\n}\n\n\nx &lt;- c(\"x1\", \"x100\", \"x2\")\nstr_sort(x)\n#&gt; [1] \"x1\"   \"x100\" \"x2\"\nstr_sort(x, numeric = TRUE)\n#&gt; [1] \"x1\"   \"x2\"   \"x100\"\n\nThis is wrapper is useful because it decouples str_sort() from the stri_opts_collator() meaning that if stri_opts_collator() gains new arguments users of str_sort() can take advantage of them immediately. But most of the arguments in stri_opts_collator() are sufficiently arcane that they don’t need to be exposed directly in stringr, which is designed to minimise the cognitive load of the user, by hiding some of the full complexity of string handling.\n(The importance of the locale argument comes up in “hidden inputs”, Chapter 5.)\nHowever, stri_opts_collator() deliberately ignores any arguments in .... This means that misspellings are silently ignored:\n\nstr_sort(x, numric = TRUE)\n#&gt; Warning in stringi::stri_opts_collator(locale, numeric = numeric, ...): Unknown\n#&gt; option to `stri_opts_collator`.\n#&gt; [1] \"x1\"   \"x100\" \"x2\"\n\nWe can work around this behaviour by adding check_dots_used() to str_sort():\n\nstr_sort &lt;- function(x, decreasing = FALSE, na_last = TRUE, locale = \"en\",  numeric = FALSE, ...) \n{\n    rlang::check_dots_used()\n  \n    stringi::stri_sort(x, \n      decreasing = decreasing, \n      na_last = na_last, \n      opts_collator = stringi::stri_opts_collator(\n        locale, \n        numeric = numeric, \n        ...\n      )\n    )\n}\n\nstr_sort(x, numric = TRUE)\n#&gt; Warning in stringi::stri_opts_collator(locale, numeric = numeric, ...): Unknown\n#&gt; option to `stri_opts_collator`.\n#&gt; Error in `str_sort()`:\n#&gt; ! Arguments in `...` must be used.\n#&gt; ✖ Problematic argument:\n#&gt; • numric = TRUE\n#&gt; ℹ Did you misspell an argument name?\n\nNote, however, that it’s better to figure out why stri_opts_collator() ignores ... in the first place. You can see that discussion at https://github.com/gagolews/stringi/issues/347.\nSee https://github.com/r-lib/devtools/issues/2016 for discussion about using this in another discussion about using this in devtools::install_github() which is an similar situation, but with a more complicated chain of calls: devtools::install_github() -&gt; install.packages() -&gt; download.file()."
  },
  {
    "objectID": "cs-mapply-pmap.html",
    "href": "cs-mapply-pmap.html",
    "title": "20  Case study: mapply() vs pmap()",
    "section": "",
    "text": "library(purrr)\n\nIt’s useful to compare mapply() to purrr::pmap(). They both are an attempt to solve a similar problem, extending lapply()/map() to handle iterating over any number of arguments.\n\nargs(mapply)\n#&gt; function (FUN, ..., MoreArgs = NULL, SIMPLIFY = TRUE, USE.NAMES = TRUE) \n#&gt; NULL\nargs(pmap)\n#&gt; function (.l, .f, ..., .progress = FALSE) \n#&gt; NULL\n\n\nx &lt;- c(\"apple\", \"banana\", \"cherry\")\npattern &lt;- c(\"p\", \"n\", \"h\")\nreplacement &lt;- c(\"x\", \"f\", \"q\")\n\nmapply(gsub, pattern, replacement, x)\n#&gt;        p        n        h \n#&gt;  \"axxle\" \"bafafa\" \"cqerry\"\n\nmapply(gsub, pattern, replacement, x)\n#&gt;        p        n        h \n#&gt;  \"axxle\" \"bafafa\" \"cqerry\"\npurrr::pmap_chr(list(pattern, replacement, x), gsub)\n#&gt; [1] \"axxle\"  \"bafafa\" \"cqerry\"\n\nHere we’ll ignore simplify = TRUE which makes mapply() type-unstable by default. I’ll also ignore USE.NAMES = TRUE which isn’t just about using names, but about using character vector input as names for output. I think it’s reused from lapply() without too much thought as it’s only the names of the first argument that matter.\n\nmapply(toupper, letters[1:3])\n#&gt;   a   b   c \n#&gt; \"A\" \"B\" \"C\"\nmapply(toupper, letters[1:3], USE.NAMES = FALSE)\n#&gt; [1] \"A\" \"B\" \"C\"\nmapply(toupper, setNames(letters[1:3], c(\"X\", \"Y\", \"Z\")))\n#&gt;   X   Y   Z \n#&gt; \"A\" \"B\" \"C\"\n\npmap_chr(list(letters[1:3]), toupper)\n#&gt; [1] \"A\" \"B\" \"C\"\n\nmapply() takes the function to apply as the first argument, followed by an arbitrary number of arguments to pass to the function. This makes it different to the other apply() functions (including lapply(), sapply() and tapply()), which take the data as the first argument. mapply() could take ... as the first arguments, but that would force FUN to always be named, which would also make it inconsistent with the other apply() functions.\npmap() avoids this problem by taking a list of vectors, rather than individual vectors in .... This allows pmap() to use ... for another purpose, instead of the MoreArg argument (a list), pmap() passes ... on to .f.\n\nmapply(gsub, pattern, replacement, x, fixed = TRUE)\n#&gt;        p        n        h \n#&gt;  \"axxle\" \"bafafa\" \"cqerry\"\npurrr::pmap_chr(list(pattern, replacement, x), gsub, fixed = TRUE)\n#&gt; [1] \"axxle\"  \"bafafa\" \"cqerry\"\n\nThere’s a subtle difference here that doesn’t matter in most cases - in the mapply() fixed is recycled to the same length as pattern whereas it is not pmap(). TODO: figure out example where that’s more clear.\n(Also note that pmap() uses the . prefix to avoid the problem described in Chapter Chapter 18.)"
  },
  {
    "objectID": "cs-setNames.html#what-does-setnames-do",
    "href": "cs-setNames.html#what-does-setnames-do",
    "title": "\n21  Case study: setNames()\n",
    "section": "\n21.1 What does setNames() do?",
    "text": "21.1 What does setNames() do?\nstats::setNames() is a shorthand that allows you to set vector names inline (it’s a little surprising that it lives in the stats package). It has a simple definition:\n\nsetNames &lt;- function(object = nm, nm) {\n  names(object) &lt;- nm\n  object\n}\n\nAnd is easy to use:\n\n# Instead of\nx &lt;- 1:3\nnames(x) &lt;- c(\"a\", \"b\", \"c\")\n\n# Can write\nx &lt;- setNames(1:3, c(\"a\", \"b\", \"c\"))\nx\n#&gt; a b c \n#&gt; 1 2 3\n\nThis function is short (just two lines of code!) but yields a surprisingly rich analysis."
  },
  {
    "objectID": "cs-setNames.html#how-can-we-improve-the-names",
    "href": "cs-setNames.html#how-can-we-improve-the-names",
    "title": "\n21  Case study: setNames()\n",
    "section": "\n21.2 How can we improve the names?",
    "text": "21.2 How can we improve the names?\nFirstly, I prefer snake_case to camelCase, so I’d call the function set_names(). Then we need to consider the arguments:\n\nI think the first argument, object, would be better called x in order to emphasise that this function only works with vectors (because only vectors have names).\nThe second argument, nm is rather terse, and I don’t see any disadvantage in calling it names. I think you could also argue that it should be called y since its meaning should be obvious from the function name.\n\nThis yields:\n\nset_names &lt;- function(x = names, names) {\n  names(x) &lt;- names\n  x\n}"
  },
  {
    "objectID": "cs-setNames.html#what-about-the-default-values",
    "href": "cs-setNames.html#what-about-the-default-values",
    "title": "\n21  Case study: setNames()\n",
    "section": "\n21.3 What about the default values?",
    "text": "21.3 What about the default values?\nThe default values of setNames() are a little hard to understand, because the default value of the first argument is the second argument. It was defined this way to make it possible to name a character vector with itself:\n\nsetNames(nm = c(\"apple\", \"banana\", \"cake\"))\n#&gt;    apple   banana     cake \n#&gt;  \"apple\" \"banana\"   \"cake\"\n\nBut that decision leads to a function signature that violates one of the principles of Chapter 6: a required argument comes after an optional argument. Fortunately, we can fix this easily and still preserve the useful ability to name a vector with itself:\n\nset_names &lt;- function(x, names = x) {\n  names(x) &lt;- names\n  x\n}\n\nset_names(c(\"apple\", \"banana\", \"cake\"))\n#&gt;    apple   banana     cake \n#&gt;  \"apple\" \"banana\"   \"cake\"\n\nThis helps to emphasise that x is the primary argument."
  },
  {
    "objectID": "cs-setNames.html#what-about-bad-inputs",
    "href": "cs-setNames.html#what-about-bad-inputs",
    "title": "\n21  Case study: setNames()\n",
    "section": "\n21.4 What about bad inputs?",
    "text": "21.4 What about bad inputs?\nNow that we’ve considered how the function works with correct inputs, it’s time to consider how it should work with malformed inputs. The current function checks neither the length not the type:\n\nset_names(1:3, \"a\")\n#&gt;    a &lt;NA&gt; &lt;NA&gt; \n#&gt;    1    2    3\n\nset_names(1:3, list(letters[1:3], letters[4], letters[5:6]))\n#&gt; c(\"a\", \"b\", \"c\")                d      c(\"e\", \"f\") \n#&gt;                1                2                3\n\nWe can resolve this by asserting that the names should always be a character vector, and should have the same length as x:\n\nset_names &lt;- function(x, names = x) {\n  if (!is.character(names) || length(names) != length(x)) {\n    stop(\"`names` must be a character vector the same length as `x`.\", call. = FALSE)\n  }\n  \n  names(x) &lt;- names\n  x\n}\n\nset_names(1:3, \"a\")\n#&gt; Error: `names` must be a character vector the same length as `x`.\nset_names(1:3, list(letters[1:3], letters[4], letters[5:6]))\n#&gt; Error: `names` must be a character vector the same length as `x`.\n\nYou could also frame this test using vctrs assertions:\n\nlibrary(vctrs)\n\nset_names &lt;- function(x, names = x) {\n  vec_assert(x)\n  vec_assert(names, ptype = character(), size = length(x))\n\n  names(x) &lt;- names\n  x\n}\n\nNote that I slipped in an assertion that x should be a vector. This slightly improves the error message if you accidentally supply the wrong sort of input to set_names():\n\nsetNames(mean, 1:3)\n#&gt; Error in names(object) &lt;- nm: names() applied to a non-vector\nset_names(mean, 1:3)\n#&gt; Error in `set_names()`:\n#&gt; ! `x` must be a vector, not a function.\n\nNote that we’re simply checking the length of names here, rather than recycling it, i.e. the invariant is vec_size(set_names(x, y)) is vec_size(x), not vec_size_common(x, y). I think this is the correct behaviour because you usually add names to a vector to create a lookup table, and a lookup table is not useful if there are duplicated names. This makes set_names() less general in return for better error messages when you do something suspicious (and you can always use an explicit rep_along() if do want this behaviour.)"
  },
  {
    "objectID": "cs-setNames.html#how-could-we-extend-this-function",
    "href": "cs-setNames.html#how-could-we-extend-this-function",
    "title": "\n21  Case study: setNames()\n",
    "section": "\n21.5 How could we extend this function?",
    "text": "21.5 How could we extend this function?\nNow that we’ve modified the function so it doesn’t violate the principles in this book, we can think about how we might extend it. Currently the function is only useful for setting names to a constant. Maybe we could extend it to also make it easier to change existing names? One way to do that would be to allow names to be a function:\n\nset_names &lt;- function(x, names = x) {\n  vec_assert(x)\n  \n  if (is.function(names)) {\n    names &lt;- names(base::names(x))\n  }\n  vec_assert(names, ptype = character(), size = length(x))\n\n  names(x) &lt;- names\n  x\n}\n\nx &lt;- c(a = 1, b = 2, c = 3)\nset_names(x, toupper)\n#&gt; A B C \n#&gt; 1 2 3\n\nWe could also support anonymous function formula shortcut used in many places in the tidyverse.\n\nset_names &lt;- function(x, names = x) {\n  vec_assert(x)\n  \n  if (is.function(names) || rlang::is_formula(names)) {\n    fun &lt;- rlang::as_function(names)\n    names &lt;- fun(base::names(x))\n  }\n  vec_assert(names, ptype = character(), size = length(x))\n\n  names(x) &lt;- names\n  x\n}\n\nx &lt;- c(a = 1, b = 2, c = 3)\nset_names(x, ~ paste0(\"x-\", .))\n#&gt; x-a x-b x-c \n#&gt;   1   2   3\n\nNow set_names() supports overriding and modifying names. What about removing them? It turns out that setNames() supported this, but our stricter checks prohibit:\n\nx &lt;- c(a = 1, b = 2, c = 3)\nsetNames(x, NULL)\n#&gt; [1] 1 2 3\nset_names(x, NULL)\n#&gt; Error in `set_names()`:\n#&gt; ! `names` must be a vector, not `NULL`.\n\nWe can fix this with another clause:\n\nset_names &lt;- function(x, names = x) {\n  vec_assert(x)\n  \n  if (!is.null(names)) {\n    if (is.function(names) || rlang::is_formula(names)) {\n      fun &lt;- rlang::as_function(names)\n      names &lt;- fun(base::names(x))\n    }\n    \n  }\n\n  names(x) &lt;- names\n  x\n}\n\nx &lt;- c(a = 1, b = 2, c = 3)\nset_names(x, NULL)\n#&gt; [1] 1 2 3\n\nHowever, I think this has muddied the logic. To resolve it, I think we should pull out the checking code into a separate function. After trying out a few approaches, I ended up with:\n\ncheck_names &lt;- function(names, x) {\n  if (is.null(names)) {\n    names\n  } else if (vec_is(names)) {\n    vec_assert(names, ptype = character(), size = length(x))  \n  } else if (is.function(names)) {\n    check_names_2(names(base::names(x)), x)\n  } else if (rlang::is.formula(names)) {\n    check_names_2(rlang::as_function(names), x)\n  } else {\n    rlang::abort(\"`names` must be NULL, a function or formula, or a vector\")\n  }\n}\n\nThis then replaces vec_assert() in set_names(). I separate the input checking and implementation with a blank line to help visually group the parts of the function.\n\nset_names &lt;- function(x, names = x) {\n  vec_assert(x)\n  names &lt;- check_names(names, x)\n  \n  names(x) &lt;- names\n  x\n}\n\nWe could simplify the function even further, but I think this is a bad idea becaues it mingles input validation with implementation:\n\n# Don't do this\nset_names &lt;- function(x, names = x) {\n  vec_assert(x)\n  names(x) &lt;- check_names(names, x)\n  x\n}\n\n# Or even\nset_names &lt;- function(x, names = x) {\n  `names&lt;-`(vec_assert(x), check_names(names, x))\n}"
  },
  {
    "objectID": "cs-setNames.html#compared-to-rlangset_names",
    "href": "cs-setNames.html#compared-to-rlangset_names",
    "title": "\n21  Case study: setNames()\n",
    "section": "\n21.6 Compared to rlang::set_names()\n",
    "text": "21.6 Compared to rlang::set_names()\n\nIf you’re familiar with rlang, you might notice that we’ve ended up with something rather similar to rlang::set_names(). However, these careful analysis in this chapter has lead to a few differences. rlang::set_names():\n\nCalls the second argument nm, instead of something more descriptive. I think this is simply because we never sat down and fully considered the interface.\nCoerces nm to character vector. This allows rlang::set_names(1:4) to automatically name the vector, but this seems a relatively weak new feature in return for the cost of not throwing an error message if you provide an unsual vector type. (Both lists and data frames have as.character() methods so this will work for basically any type of vector, even if completely inappropriate.)\nPasses ... on to function nm. I now think that decision was a mistake: it substantially complicates the interface in return for a relatively small investment."
  },
  {
    "objectID": "independent-usage.html#whats-the-problem",
    "href": "independent-usage.html#whats-the-problem",
    "title": "22  Argument usage should be independent",
    "section": "\n22.1 What’s the problem?",
    "text": "22.1 What’s the problem?\nAvoid complex patterns of dependencies between arguments so that only certain combinations can be used at the same time.\nDependencies between arguments makes functions harder:\n\nIt can suggest that there are many more viable combination of inputs than actually exist and those unnecessary possibilities still occupy head space. You have to learn and the remember the set of allowed combinations, rather than them being implied by the structure of the function.\nIt makes documentation harder to write. You have to use extra words to explain exactly how combinations of arguments work together, and it’s not obvious where those words should go. If there’s an interaction between arg_a and arg_b do you document with arg_a, with arg_b, or with both?\n\nThere are two exceptions to this pattern that we’ll come back to in future chapters:\n\n\nChapter 24: sometimes you need a pair of mutual exclusive arguments.\n\nChapter 25: sometimes you want to provide all the data in a single argument, and other times it’s useful to spread the same data across multiple arguments."
  },
  {
    "objectID": "independent-usage.html#what-are-some-examples",
    "href": "independent-usage.html#what-are-some-examples",
    "title": "22  Argument usage should be independent",
    "section": "\n22.2 What are some examples?",
    "text": "22.2 What are some examples?\n\nforcats::fct_lump() decides which algorithm to use based on a combination of the n and prop arguments.\nIn ggplot2::geom_histogram(), you can specify the histogram breaks in three ways: as a number of bins, as the width of each bin (binwidth, plus center or boundary), or the exact breaks. You can only pick one of the three options, which is hard to convey in the documentation. There’s also an implied precedence so that if more than one option is supplied, one will silently win.\nIn readr::locale() there’s a complex dependency between decimal_mark and grouping_mark because they can’t be the same value, and Europe and the US Europe use different standards.\nIn ggplot2::scale_x_date() and friends you can specify the breaks and labels either with breaks and labels (like all other scale functions) or with date_breaks and date_labels.\ngrepl() has perl, fixed, and ignore.case arguments which can either be TRUE or FALSE. If these arguments were independent that would imply 2^3 = 8 possible combinations. But fixed = TRUE overrides perl = TRUE, and ignore.case = TRUE only works if fixed = FALSE so there are only 5 valid combinations.\n\nIn rep() you can supply both times and each unless times is a vector :\n\nrep(1:3, times = 2, each = 3)\n#&gt;  [1] 1 1 1 2 2 2 3 3 3 1 1 1 2 2 2 3 3 3\nrep(1:3, times = 1:3, each = 2)\n#&gt; Error in rep(1:3, times = 1:3, each = 2): invalid 'times' argument\n\nLearn more in Chapter 12.\n\n\n(Other examples for you to explore: na.rm and use in var(). Why does this arise?)"
  },
  {
    "objectID": "independent-usage.html#how-do-i-remediate-past-mistakes",
    "href": "independent-usage.html#how-do-i-remediate-past-mistakes",
    "title": "22  Argument usage should be independent",
    "section": "\n22.3 How do I remediate past mistakes?",
    "text": "22.3 How do I remediate past mistakes?\nOften these problems arise because the scope of a function grows over time. The scope of a function was small when it was initially designed but it has grown incrementally over time. At no point did it seem worth the additional effort to refactor to a new design, but now you have a large complex function. This makes the problem hard to avoid.\nTo remediate the problem, you’ll need to think holistically and reconsider the complete interface. There are two common outcomes which are illustrated in the case studies below:\n\nSplitting the function into multiple functions that each do one thing.\nEncapsulating related details arguments into a single object.\n\nIf these changes to the interface occur to exported functions in a package, you’ll need to consider how to preserve the interface with deprecation warnings. For important functions, it is worth generating an message that includes new code to copy and paste.\n\n22.3.1 Splitting into multiple functions\nThe goal of fct_lump() is to combine infrequent factor levels into a common “other” level, which is useful for displays where you want to concentrate on the most common values but still account for every observation. When I first wrote fct_lump(), it implemented a single strategy. But over time people asked for more and more variations, which I kept adding to fct_lump(). This lead to a function that picks from one of three different strategies depending which of the n and prop arguments you supply:\n\nIf n and prop are missing, it will merge together the least frequent levels, ensuring that other is still the smallest level. This case ignores the ties.method argument, adding another dependency between arguments.\nIf a positive n is supplied, it preserves the n most common values; if a negative n is supplied it preserves the n least common values.\nIf a positive prop is supplied, lumps values which do not appear at least prop of the time. Negative prop lumps values that do not appear at most -prop of the time.\n\nOverall, this become very hard to explain in the documentation, so in forcats 0.5.0 we split fct_lump() into three separate functions: fct_lump_prop(), fct_lump_n(), and fct_lump_lowfreq(). This allows the function name to hint at the purpose, prevents you from supplying both n and prop through the design of the functions, and only has the ties.method argument where it makes sense.\n\n22.3.2 Using an enumeration\n\n22.3.3 Creating a details object\nGenerating the bins for a histogram is a surprisingly complex topic. stat_bin(), which powers geom_histogram(), has a total of 5 arguments that control where the bins are placed: binwidth, bins1, boundary, breaks, and closed. They have a complex set of interdependencies, which have a choose your own adventure feel. Firstly you can select been breaks, bins, and binwidths. Then if you pick bins or binwidths, you can also optionally selected center or boundary. binwidth can also be a function, in which case it’s called individually on each layer. If we’re going to clean up these arguments, it would also be nice to consider how you might supply a custom breaks for each layer (this would make it easier to implement an equal area histogram, which currently requires an custom stat, as in https://github.com/eliocamp/ggpercentogram/).\nOne way to resolve this tension would be to use a single argument that takes objects created by a helper functions, e.g.:\n\nbins = bin_width(width, center, boundary)\nbins = bin_number(n, center, boundary)\nbins = bin_breaks(breaks)\n\n(where center and boundary would be mutually exclusive, Chapter 24)\nThis is a bit verbose for the most common case where you just want to set the width of the bins. You could automatically wrap a bare number in bin_width(), but bins = 10 seems more likely to imply"
  },
  {
    "objectID": "independent-usage.html#see-also",
    "href": "independent-usage.html#see-also",
    "title": "22  Argument usage should be independent",
    "section": "\n22.4 See also",
    "text": "22.4 See also\nSee Chapter 23 the related problem of one argument affecting the interpretation of another argument."
  },
  {
    "objectID": "independent-usage.html#footnotes",
    "href": "independent-usage.html#footnotes",
    "title": "22  Argument usage should be independent",
    "section": "",
    "text": "center is also a little problematic as an argument name, because UK English would prefer centre. It’s probably ok here since this it’s a very rarely used argument, but middle would be a reasonable alternative that doesn’t have the same problem↩︎"
  },
  {
    "objectID": "independent-meaning.html#whats-the-problem",
    "href": "independent-meaning.html#whats-the-problem",
    "title": "23  Argument meaning should be independent",
    "section": "\n23.1 What’s the problem?",
    "text": "23.1 What’s the problem?\nAvoid having one argument change the interpretation of another argument.\nThis makes reading function calls harder because if the argument that changes meaning comes after the argument who’s meaning is changed you need to reinterpret the rest of the call."
  },
  {
    "objectID": "independent-meaning.html#what-are-some-examples",
    "href": "independent-meaning.html#what-are-some-examples",
    "title": "23  Argument meaning should be independent",
    "section": "\n23.2 What are some examples?",
    "text": "23.2 What are some examples?\n\n\nIn library() the character.only argument changes how the package argument is interpreted:\n\nggplot2 &lt;- \"dplyr\"\n\n# Loads ggplot2\nlibrary(ggplot2)\n\n# Loads dplyr\nlibrary(ggplot2, character.only = TRUE)\n\n\nIn install.packages() setting repos = NULL changes the interpretation of pkgs from being a vector of package names to a vector of file paths.\nIn the base R string functions, perl and fixed change the interpretation of the pattern argument. See Section 26.3 for more details.\nIn ggplot2::geom_label(), setting parse = TRUE changes the meaning of the label argument/aesthetic from being any string to be a string on unparsed R code."
  },
  {
    "objectID": "independent-meaning.html#how-do-i-remediate-past-mistakes",
    "href": "independent-meaning.html#how-do-i-remediate-past-mistakes",
    "title": "23  Argument meaning should be independent",
    "section": "\n23.3 How do I remediate past mistakes?",
    "text": "23.3 How do I remediate past mistakes?"
  },
  {
    "objectID": "independent-meaning.html#see-also",
    "href": "independent-meaning.html#see-also",
    "title": "23  Argument meaning should be independent",
    "section": "\n23.4 See also",
    "text": "23.4 See also\nChapter 22 discusses the related problem of when using one argument affects which other arguments can be used."
  },
  {
    "objectID": "mutually-exclusive-arguments.html#whats-the-pattern",
    "href": "mutually-exclusive-arguments.html#whats-the-pattern",
    "title": "24  Mutually exclusive arguments",
    "section": "\n24.1 What’s the pattern?",
    "text": "24.1 What’s the pattern?"
  },
  {
    "objectID": "mutually-exclusive-arguments.html#what-are-some-examples",
    "href": "mutually-exclusive-arguments.html#what-are-some-examples",
    "title": "24  Mutually exclusive arguments",
    "section": "\n24.2 What are some examples?",
    "text": "24.2 What are some examples?\nA number of functions that allow you to supply exactly one of two possible arguments:\n\nread.table() allows you to supply data either with a path to a file, or inline as text.\nrvest::html_element() allows you to select HTML elements either with a css selector or an xpath expression.\nforcats::fct_other() allows you to either keep or drop specified factor values."
  },
  {
    "objectID": "mutually-exclusive-arguments.html#how-do-you-use-this-pattern",
    "href": "mutually-exclusive-arguments.html#how-do-you-use-this-pattern",
    "title": "24  Mutually exclusive arguments",
    "section": "\n24.3 How do you use this pattern?",
    "text": "24.3 How do you use this pattern?\nIf you use this technique, use xor() and missing() to check that exactly one argument is supplied:\n\nfct_drop &lt;- function(f, drop, keep) {\n  if (!xor(missing(keep), missing(drop))) {\n    stop(\"Must supply exactly one of `keep` and `drop`\")\n  }  \n}\nfct_drop(factor())\n#&gt; Error in fct_drop(factor()): Must supply exactly one of `keep` and `drop`\n\nfct_drop(factor(), keep = \"a\", drop = \"b\")\n#&gt; Error in fct_drop(factor(), keep = \"a\", drop = \"b\"): Must supply exactly one of `keep` and `drop`\n\nOr the helper rlang::check_exclusive():\n\nfct_drop &lt;- function(f, drop, keep) {\n  rlang::check_exclusive(drop, keep)\n}\nfct_drop(factor())\n#&gt; Error in `fct_drop()`:\n#&gt; ! One of `drop` or `keep` must be supplied.\n\nfct_drop(factor(), keep = \"a\", drop = \"b\")\n#&gt; Error in `fct_drop()`:\n#&gt; ! Exactly one of `drop` or `keep` must be supplied.\n\nAnd in the documentation, make it clear that only one of the pair can be supplied:\n\n#' @param keep,drop Pick one of `keep` and `drop`:\n#'   * `keep` will preserve listed levels, replacing all others with \n#'     `other_level`.\n#'   * `drop` will replace listed levels with `other_level`, keeping all\n#'     as is.\n\nThis technique should only be used for are exactly two possible arguments. If there are more than two, that is generally a sign you should create more functions. See case studies in Chapter 12 and Section 22.3.1 for examples."
  },
  {
    "objectID": "compound-arguments.html#whats-the-pattern",
    "href": "compound-arguments.html#whats-the-pattern",
    "title": "25  Compound arguments",
    "section": "\n25.1 What’s the pattern?",
    "text": "25.1 What’s the pattern?\nA related, if less generally useful, form is to allow the user to supply either a single complex argument or several smaller arguments."
  },
  {
    "objectID": "compound-arguments.html#what-are-some-examples",
    "href": "compound-arguments.html#what-are-some-examples",
    "title": "25  Compound arguments",
    "section": "\n25.2 What are some examples?",
    "text": "25.2 What are some examples?\n\nrgb(cbind(r, g, b)) is equivalent to rgb(r, g, b) (See Chapter 16 for more details).\noptions(list(a = 1, b = 2)) is equivalent to options(a = 1, b = 2).\nstringr::str_sub(x, cbind(start, end)) is equivalent to str_sub(x, start, end).\n\nThe most compelling reason to provide this sort of interface is when another function might return a complex output that you want to use as an input. For example, it seems reasonable that you should be able to feed the output of str_locate() directly into str_sub():\n\nlibrary(stringr)\n\nx &lt;- c(\"aaaaab\", \"aaab\", \"ccccb\")\nloc &lt;- str_locate(x, \"a+b\")\n\nstr_sub(x, loc)\n#&gt; [1] \"aaaaab\" \"aaab\"   NA\n\nBut equally, it would be a bit weird to have to provide a matrix when subsetting with known positions:\n\nstr_sub(\"Hadley\", cbind(2, 4))\n#&gt; [1] \"adl\"\n\nSo str_sub() allows either individual vectors supplied to start and end, or a two-column matrix supplied to start."
  },
  {
    "objectID": "compound-arguments.html#how-do-i-use-the-pattern",
    "href": "compound-arguments.html#how-do-i-use-the-pattern",
    "title": "25  Compound arguments",
    "section": "\n25.3 How do I use the pattern?",
    "text": "25.3 How do I use the pattern?\nTo implement in your own functions, you should branch on the type of the first argument:\n\nstr_sub &lt;- function(string, start, end) {\n  if (is.matrix(start)) {\n    if (!missing(end)) {\n      stop(\"`end` must be missing when `start` is a matrix\", call. = FALSE)\n    }\n    if (ncol(start) != 2) {\n      stop(\"Matrix `start` must have exactly two columns\", call. = FALSE)\n    }\n    stri_sub(string, from = start[, 1], to = start[, 2])\n  } else {\n    stri_sub(string, from = start, to = end)\n  }\n}\n\nAnd make it clear in the documentation:\n\n#' @param start,end Integer vectors giving the `start` (default: first)\n#'   and `end` (default: last) positions, inclusively. Alternatively, you\n#'   pass a two-column matrix to `start`, i.e. `str_sub(x, start, end)`\n#'   is equivalent to `str_sub(x, cbind(start, end))`\n\n(If you look at string::str_sub() you’ll notice that start and end do have defaults; I think this is a mistake because start and end are important enough that the user should always be forced to supply them.)"
  },
  {
    "objectID": "cs-stringr.html#function-names",
    "href": "cs-stringr.html#function-names",
    "title": "\n26  Case study: stringr\n",
    "section": "\n26.1 Function names",
    "text": "26.1 Function names\nWhen the base regular expression functions were written, most R users were familiar with the command line and tools like grepl. This made naming R’s string manipulation functions after these tools seem natural. When I started work on stringr, the majority of R users were not familiar with linux or the command line, so it made more sense to start afresh.\nI think there were successes and failures here. On the whole, I think str_replace_all(), str_locate(), and str_detect() are easier to remember than gsub(), regexpr(), and grepl(). However, it’s harder to remember what makes str_subset() and str_which() different. If I was to do stringr again, I would make more of an effort to distinguish between functions that operated on individual matches and individual strings as str_locate() and str_which() seem like their names should be more closely related as str_locate() returns the location of a match within each string in the vector, and str_subset() returns the matching locations within a vector."
  },
  {
    "objectID": "cs-stringr.html#argument-order-and-names",
    "href": "cs-stringr.html#argument-order-and-names",
    "title": "\n26  Case study: stringr\n",
    "section": "\n26.2 Argument order and names",
    "text": "26.2 Argument order and names\nBase R string functions mostly have pattern as the first argument, with the chief exception being strsplit(). stringr functions always have string as the first argument.\nI regret using string; I now think x would be a more appropriate name."
  },
  {
    "objectID": "cs-stringr.html#sec-pattern-engine",
    "href": "cs-stringr.html#sec-pattern-engine",
    "title": "\n26  Case study: stringr\n",
    "section": "\n26.3 Selecting a pattern engine",
    "text": "26.3 Selecting a pattern engine\ngrepl(), has three arguments that take either FALSE or TRUE: ignore.case, perl, fixed, which might suggest that there are 2 ^ 3 = 8 possible options. But fixed = TRUE overrides perl = TRUE, and ignore.case = TRUE only works if fixed = FALSE so there are only 5 valid combinations.\n\nx &lt;- grepl(\"a\", letters, fixed = TRUE, ignore.case = TRUE)\n#&gt; Warning in grepl(\"a\", letters, fixed = TRUE, ignore.case = TRUE): argument\n#&gt; 'ignore.case = TRUE' will be ignored\nx &lt;- grepl(\"a\", letters, fixed = TRUE, perl = TRUE)\n#&gt; Warning in grepl(\"a\", letters, fixed = TRUE, perl = TRUE): argument 'perl =\n#&gt; TRUE' will be ignored\n\nIt’s easier to understand fixed and perl once you realise their combination is used to pick from one of three engines for matching text:\n\nThe default is POSIX 1003.2 extended regular expressions.\n\nperl = TRUE uses Perl-style regular expressions.\n\nfixed = TRUE uses fixed matching.\n\nThis makes it clear why perl = TRUE and fixed = TRUE isn’t permitted: you’re trying to pick two conflicting engines.\nAn alternative interface that makes this choice more clear would be to use Chapter 10 and create a new argument called something like engine = c(\"POSIX\", \"perl\", \"fixed\"). This also has the nice feature of making it easier to extend in the future. That might look something like this:\n\ngrepl(pattern, string, engine = \"regex\")\ngrepl(pattern, string, engine = \"fixed\")\ngrepl(pattern, string, engine = \"perl\")\n\nBut stringr takes a different approach, because of a problem hinted at in grepl() and friends: ignore.case only works with two of the three engines: POSIX and perl. Additionally, having an engine argument that affects the meaning of the pattern argument is a little unfortunate — that means you have to read the call until you see the engine argument before you can understand precisely what the pattern means.\nstringr takes a different approach, encoding the engine as an attribute of the pattern:\n\nx &lt;- str_detect(letters, \"a\")\n# short for:\nx &lt;- str_detect(letters, regex(\"a\"))\n\n# Which is where you supply additional arguments\nx &lt;- str_detect(letters, regex(\"a\", ignore_case = TRUE))\n\nThis has the advantage that each engine can take different arguments. In base R, the only argument of this nature of ignore.case, but stringr’s regex() has arguments like multiline, comments, and dotall which change how some components of the pattern are matched.\nUsing an engine argument also wouldn’t work in stringr because of the boundary() engine which rather than matching specific patterns uses matches based on boundaries between things like letters or words or sentences.\n\nstr_view(\"This is a sentence.\", boundary(\"word\"))\nstr_view(\"This is a sentence.\", boundary(\"sentence\"))\n\nThis is more appealing than creating a separate function for each engine because there are many other functions in the same family as grepl(). If we created grepl_fixed(), we’d also need gsub_fixed(), regexp_fixed() etc."
  },
  {
    "objectID": "cs-stringr.html#str_flatten",
    "href": "cs-stringr.html#str_flatten",
    "title": "\n26  Case study: stringr\n",
    "section": "\n26.4 str_flatten()\n",
    "text": "26.4 str_flatten()\n\nstr_flatten() was a relatively recent addition to stringr. It took me a long time to realise that one of the challenges of understanding paste() was that depending on the presence or absence of the collapse argument it could either transform a string (i.e. return something the same length) or summarise a string (i.e. always return a single string).\nOnce str_flatten() existed it become more clear that it would be useful to have str_flatten_comma() which made it easier to use the Oxford comma (which seems to be something that’s only needed for English, and ironically the Oxford comma is more common in US English than UK English)."
  },
  {
    "objectID": "cs-stringr.html#recycling-rules",
    "href": "cs-stringr.html#recycling-rules",
    "title": "\n26  Case study: stringr\n",
    "section": "\n26.5 Recycling rules",
    "text": "26.5 Recycling rules\nstringr implements recycling rules so that you can either supply a vector of strings or a vector of patterns:\n\nalphabet &lt;- str_flatten(letters, collapse = \"\")\nvowels &lt;- c(\"a\", \"e\", \"i\", \"o\", \"u\")\ngrepl(vowels, alphabet)\n#&gt; Warning in grepl(vowels, alphabet): argument 'pattern' has length &gt; 1 and only\n#&gt; the first element will be used\n#&gt; [1] TRUE\nstr_detect(alphabet, vowels)\n#&gt; [1] TRUE TRUE TRUE TRUE TRUE\n\nOn the whole I regret this. It’s generally not that useful (since you typically have more than one string, not more than one pattern), most people don’t use it, and now it feels overly clever."
  },
  {
    "objectID": "cs-stringr.html#redundant-functions",
    "href": "cs-stringr.html#redundant-functions",
    "title": "\n26  Case study: stringr\n",
    "section": "\n26.6 Redundant functions",
    "text": "26.6 Redundant functions\nThere are a couple of stringr functions that were very useful at the time, but are now less important.\n\n\nnchar(NA) used to return 2, and nchar(factor(\"abc\")) used to return 1. str_length() fixed both of these problems, but those fixes also migrated to base R, leaving str_length() as less useful.\n\npaste0() did not exist so str_c() was very useful. But now str_c() primarily only useful for its recycling logic."
  },
  {
    "objectID": "out-multi.html#different-sizes",
    "href": "out-multi.html#different-sizes",
    "title": "27  Returning multiple values",
    "section": "\n27.1 Different sizes",
    "text": "27.1 Different sizes\nUse a list. Name it.\nIf you return the same type of output from multiple functions, you should create a function that consistently creates exact the same format (to avoid accidentally inconsistency), and consider making it an S3 class (so you can have a custom print method)."
  },
  {
    "objectID": "out-multi.html#same-size",
    "href": "out-multi.html#same-size",
    "title": "27  Returning multiple values",
    "section": "\n27.2 Same size",
    "text": "27.2 Same size\nWhen a function returns two vectors of the same size, as a general rule should you return a tibble:\n\nA matrix would only work if the vectors were the same type (and not factor or Date), doesn’t make it easy to extract the individual values, and is not easily input to other tidyverse functions.\nA list doesn’t capture the constraint that both vectors are the same length.\nA data frame is ok if you don’t want to take a dependency on tibble, but you need to remember the drawbacks: if the columns are character vectors you’ll need to remember to use stringsAsFactors = FALSE, and the print method is confusing for list- and df-cols (and you have to create by modifying an existing data frame, not by calling data.frame()). (Example: it would be weird if glue returned tibbles from a function.)"
  },
  {
    "objectID": "out-multi.html#case-study-str_locate",
    "href": "out-multi.html#case-study-str_locate",
    "title": "27  Returning multiple values",
    "section": "\n27.3 Case study: str_locate()\n",
    "text": "27.3 Case study: str_locate()\n\ne.g. str_locate(), str_locate_all()\nInteraction with str_sub()."
  },
  {
    "objectID": "out-type-stability.html#simple-examples",
    "href": "out-type-stability.html#simple-examples",
    "title": "28  Type-stability",
    "section": "\n28.1 Simple examples",
    "text": "28.1 Simple examples\n\npurrr::map() and base::lapply() are trivially type-stable because they always return lists.\n\npaste() is type stable because it always returns a character vector.\n\nvec_ptype(paste(1))\n#&gt; character(0)\nvec_ptype(paste(\"x\"))\n#&gt; character(0)\n\n\n\nbase::mean(x) almost always returns the same type of output as x. For example, the mean of a numeric vector is a numeric vector, and the mean of a date-time is a date-time.\n\nvec_ptype(mean(1))\n#&gt; numeric(0)\nvec_ptype(mean(Sys.time()))\n#&gt; POSIXct of length 0\n\n\n\nifelse() is not type-stable because the output type depends on the value:\n\nvec_ptype(ifelse(NA, 1L, 2))\n#&gt; &lt;unspecified&gt; [0]\nvec_ptype(ifelse(FALSE, 1L, 2))\n#&gt; numeric(0)\nvec_ptype(ifelse(TRUE, 1L, 2))\n#&gt; integer(0)"
  },
  {
    "objectID": "out-type-stability.html#more-complicated-examples",
    "href": "out-type-stability.html#more-complicated-examples",
    "title": "28  Type-stability",
    "section": "\n28.2 More complicated examples",
    "text": "28.2 More complicated examples\nSome functions are more complex because they take multiple input types and have to return a single output type. This includes functions like c() and ifelse(). The rules governing base R functions are idiosyncratic, and each function tends to apply it’s own slightly different set of rules. Tidy functions should use the consistent set of rules provided by the vctrs package."
  },
  {
    "objectID": "out-type-stability.html#challenge-the-median",
    "href": "out-type-stability.html#challenge-the-median",
    "title": "28  Type-stability",
    "section": "\n28.3 Challenge: the median",
    "text": "28.3 Challenge: the median\nA more challenging example is median(). The median of a vector is a value that (as evenly as possible) splits the vector into a lower half and an upper half. In the absence of ties, mean(x &gt; median(x)) == mean(x &lt;= median(x)) == 0.5. The median is straightforward to compute for odd lengths: you simply order the vector and pick the value in the middle, i.e. sort(x)[(length(x) - 1) / 2]. It’s clear that the type of the output should be the same type as x, and this algorithm can be applied to any vector that can be ordered.\nBut what if the vector has an even length? In this case, there’s no longer a unique median, and by convention we usually take the mean of the middle two numbers.\nIn R, this makes the median() not type-stable:\n\ntypeof(median(1:3))\n#&gt; [1] \"integer\"\ntypeof(median(1:4))\n#&gt; [1] \"double\"\n\nBase R doesn’t appear to follow a consistent principle when computing the median of a vector of length 2. Factors throw an error, but dates do not (even though there’s no date half way between two days that differ by an odd number of days).\n\nmedian(factor(1:2))\n#&gt; Error in median.default(factor(1:2)): need numeric data\nmedian(Sys.Date() + 0:1)\n#&gt; [1] \"2023-07-31\"\n\nTo be clear, the problems caused by this behaviour are quite small in practice, but it makes the analysis of median() more complex, and it makes it difficult to decide what principle you should adhere to when creating median methods for new vector classes.\n\nmedian(\"foo\")\n#&gt; [1] \"foo\"\nmedian(c(\"foo\", \"bar\"))\n#&gt; Warning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\n#&gt; argument is not numeric or logical: returning NA\n#&gt; [1] NA"
  },
  {
    "objectID": "out-type-stability.html#exercises",
    "href": "out-type-stability.html#exercises",
    "title": "28  Type-stability",
    "section": "\n28.4 Exercises",
    "text": "28.4 Exercises\n\n\nHow is a date like an integer? Why is this inconsistent?\n\nvec_ptype(mean(Sys.Date()))\n#&gt; Date of length 0\nvec_ptype(mean(1L))\n#&gt; numeric(0)"
  },
  {
    "objectID": "out-vectorisation.html",
    "href": "out-vectorisation.html",
    "title": "29  Vectorisation",
    "section": "",
    "text": "Vectorisation has two meanings: it can refer to either the interface of a function, or its implementation. We can make a precise statement about what a vectorised interface is. A function, f, is vectorised over a vector argument, x, iff f(x)[[i]] equals f(x[[i]]), i.e. we can exchange the order of subsetting and function application. This generalises naturally to more arguments: we say f is vectorised over x and y if f(x[[i]], y[[i]]) equals f(x, y)[[i]]. A function can have some arguments that are vectorised and some that are not, f(x, ...)[[i]] equals f(x[[i]], ...).\nIt is harder to define vectorised implementation. It’s necessary for a function with a vectorised implementation to have a vectorised interface, but it also must possess the property of computational efficiency. It’s hard to make this precise, but generally it means that if there is an explicit loop, that loop is written in C or C++, not in a R."
  },
  {
    "objectID": "out-invisible.html#whats-the-pattern",
    "href": "out-invisible.html#whats-the-pattern",
    "title": "30  Side-effect functions should return invisibly",
    "section": "\n30.1 What’s the pattern?",
    "text": "30.1 What’s the pattern?\nIf a function is called primarily for its side-effects, it should invisibly return a useful output. If there’s no obvious output, return the first argument. This makes it possible to use the function with in a pipeline."
  },
  {
    "objectID": "out-invisible.html#what-are-some-examples",
    "href": "out-invisible.html#what-are-some-examples",
    "title": "30  Side-effect functions should return invisibly",
    "section": "\n30.2 What are some examples?",
    "text": "30.2 What are some examples?\n\nprint(x) invisibly returns the printed object.\nx &lt;- y invisible returns y. This is what makes it possible to chain together multiple assignments x &lt;- y &lt;- z &lt;- 1\nreadr::write_csv() invisibly returns the data frame that was saved.\npurrr::walk() invisibly returns the vector iterated over.\nfs:file_copy(from, to) returns to\noptions() and par() invisibly return the previous value so you can reset with on.exit()."
  },
  {
    "objectID": "out-invisible.html#why-is-it-important",
    "href": "out-invisible.html#why-is-it-important",
    "title": "30  Side-effect functions should return invisibly",
    "section": "\n30.3 Why is it important?",
    "text": "30.3 Why is it important?\nInvisibly returning the first argument allows to call the function mid-pipe for its side-effects while allow the primary data to continue flowing through the pipe. This is useful for generating intermediate diagnostics, or for saving multiple output formats.\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(tibble)\n\nmtcars %&gt;%\n  as_tibble() %&gt;% \n  filter(cyl == 6) %&gt;% \n  print() %&gt;% \n  group_by(vs) %&gt;% \n  summarise(mpg = mean(mpg))\n#&gt; # A tibble: 7 × 11\n#&gt;     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n#&gt; 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n#&gt; 3  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n#&gt; 4  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n#&gt; 5  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n#&gt; 6  17.8     6  168.   123  3.92  3.44  18.9     1     0     4     4\n#&gt; 7  19.7     6  145    175  3.62  2.77  15.5     0     1     5     6\n#&gt; # A tibble: 2 × 2\n#&gt;      vs   mpg\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     0  20.6\n#&gt; 2     1  19.1\n\n\nlibrary(readr)\n\nmtcars %&gt;% \n  write_csv(\"mtcars.csv\") %&gt;% \n  write_tsv(\"mtcars.tsv\")\n\nunlink(c(\"mtcars.csv\", \"mtcars.tsv\"))\n\n\nlibrary(fs)\n\npaths &lt;- file_temp() %&gt;%\n  dir_create() %&gt;%\n  path(letters[1:5]) %&gt;%\n  file_create()\npaths\n#&gt; /tmp/Rtmp5RseNn/file1d0a69c2e26e/a /tmp/Rtmp5RseNn/file1d0a69c2e26e/b \n#&gt; /tmp/Rtmp5RseNn/file1d0a69c2e26e/c /tmp/Rtmp5RseNn/file1d0a69c2e26e/d \n#&gt; /tmp/Rtmp5RseNn/file1d0a69c2e26e/e\n\nFunctions that modify some global state, like options() or par(), should return the previous value of the variables. This, in combination with Chapter 25, makes it possible to easily reset the effect of the change:\n\nx &lt;- runif(1)\nold &lt;- options(digits = 3)\nx\n#&gt; [1] 0.434\n\noptions(old)\nx\n#&gt; [1] 0.4340125"
  },
  {
    "objectID": "changes-multivers.html#whats-the-pattern",
    "href": "changes-multivers.html#whats-the-pattern",
    "title": "31  Work with multiple dependency versions",
    "section": "\n31.1 What’s the pattern?",
    "text": "31.1 What’s the pattern?\nIn an ideal world, when a dependency of your package changes its interface, you want your package to work with both versions. This is more work but it has two significant advantages:\n\nThe CRAN submission process is decoupled. If your package only works with the development version of a dependency, you’ll need to carefully coordinate your CRAN submission with the dependencies CRAN submission. If your package works with both versions, you can submit first, making life easier for CRAN and for the maintainer of the dependency.\nUser code is less likely to be affected. If your package only works with the latest version of the dependency, then when a user upgrades your package, the dependency also must update. Upgrading multiple packages is more likely to affect user code than updating a single package.\n\nIn this pattern, you’ll learn how to write code designed to work with multiple versions of a dependency, and you’ll how to adapt your existing Travis configuration to test that you’ve got it right."
  },
  {
    "objectID": "changes-multivers.html#writing-code",
    "href": "changes-multivers.html#writing-code",
    "title": "31  Work with multiple dependency versions",
    "section": "\n31.2 Writing code",
    "text": "31.2 Writing code\nSometimes there will be an easy way to change the code to work with both old and new versions of the package; do this if you can! However, in most cases, you can’t, and you’ll need an if statement that runs different code for new and old versions of the package:\n\nif (dependency_has_new_interface()) {\n  # freshly written code that works with in-development dependency\n} else {\n  # existing code that works with the currently released dependency\n}\n\n(If your freshly written code uses functions that don’t exist in the CRAN version this will generate an R CMD check NOTE when you submit it to CRAN. This is one of the few NOTEs that you can explain: just mention that it’s needed for forward/backward compatibility in your submission notes.)\nWe recommend always pulling out the check out into a function so that the logic lives in one place. This will make it much easier to pull it out when it’s no longer needed, and provides a good place to document why it’s needed.\nThere are three basic approaches to implement dependency_has_new_interface():\n\nCheck the version of the package. This is recommended in most cases, but requires that the dependency author use a specific version convention.\nCheck for existence of a function.\nCheck for a specific argument value, or otherwise detect that the interface has changed.\n\n\n31.2.1 Case study: tidyr\nTo make the problem concrete so we can show of some real code, lets imagine we have a package that uses tidyr::nest(). tidyr::nest() changed substantially between 0.8.3 and 1.0.0, and so we need to write code like this:\n\nif (tidyr_new_interface()) {\n  out &lt;- tidyr::nest_legacy(df, x, y, z)\n} else {\n  out &lt;- tidyr::nest(df, c(x, y, z))\n}\n\n(As described above, when submitted to CRAN this will generate a note about missing tidyr::nest_legacy() which can be explained in the submission comments.)\nTo implement tidyr_new_interface(), we need to think about three versions of tidyr:\n\n0.8.3: the version currently on CRAN with the old interface.\n0.8.99.9000: the development version with the new interface. As usualy, the fourth component is &gt;= 9000 to indicate that it’s a development version. Note, however, that the patch version is 99; this indicates that release includes breaking changes.\n1.0.0: the future CRAN version; this is the version that will be submitted to CRAN.\n\nThe main question is how to write tidyr_new_interface(). There are three options:\n\n\nCheck that the version is greater than the development version:\n\ntidyr_new_interface &lt;- function() {\n  packageVersion(\"tidyr\") &gt; \"0.8.99\"\n}\n\nThis technique works because tidyr uses the convention that the development version of backward incompatible functions contain 99 in the third (patch) component.\n\n\nIf tidyr didn’t adopt this naming convention, we could test for the existence of unnest_legacy().\n\ntidyr_new_interface1 &lt;- function() {\n  exists(\"unnest_legacy\", asNamespace(\"tidyr\"))\n}\n\n\n\nIf the interface change was more subtle, you might have to think more creatively. If the package uses the lifecycle system, one approach would be to test for the presence of deprecated() in the function arguments:\n\ntidyr_new_interface2 &lt;- function() {\n  identical(formals(tidyr::unnest)$.drop, quote(deprecated()))\n}\n\n\n\nAll these approaches are reasonably fast, so it’s unlikely they’ll have any impact on performance unless called in a very tight loop.\n\nbench::mark(\n  version = tidyr_new_interface(),\n  exists =  tidyr_new_interface1(),\n  formals = tidyr_new_interface2() \n)[1:5]\n#&gt; # A tibble: 3 × 5\n#&gt;   expression      min   median `itr/sec` mem_alloc\n#&gt;   &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;\n#&gt; 1 version     516.9µs  666.1µs     1413.    4.01KB\n#&gt; 2 exists        3.2µs    4.3µs   197861.    3.29MB\n#&gt; 3 formals       1.4µs    1.7µs   399790.        0B\n\nIf you do need to use packageVersion() inside a performance sensitive function, I recommend caching the result in .onLoad() (which, by convention, lives in zzz.R). There a few ways to do this; but the following block shows one approach that matches the function interface I used above:\n\ntidyr_new_interface &lt;- function() FALSE\n.onLoad &lt;- function(...) {\n  if (utils::packageVersion(\"tidyr\") &gt; \"0.8.2\") {\n    tidyr_new_interface &lt;&lt;- function() TRUE\n  }\n}"
  },
  {
    "objectID": "changes-multivers.html#testing-with-multiple-package-versions",
    "href": "changes-multivers.html#testing-with-multiple-package-versions",
    "title": "31  Work with multiple dependency versions",
    "section": "\n31.3 Testing with multiple package versions",
    "text": "31.3 Testing with multiple package versions\nIt’s good practice to test both old and new versions of the code, but this is challenging because you can’t both sets of tests in the same R session. The easiest way to make sure that both versions are work and stay working is to use Travis.\nBefore the dependency is released, you can manually install the development version using remotes::install_github():\nmatrix:\n  include:\n  - r: release\n    name: tidyr-devel\n    before_script: Rscript -e \"remotes::install_github('tidyverse/tidyr')\"\nIt’s not generally that important to check that your code continues to work with an older version of the package, but if you want to you can use remotes::install_version():\nmatrix:\n  include:\n  - r: release\n    name: tidyr-0.8\n    before_script: Rscript -e \"remotes::install_version('tidyr', '0.8.3')\""
  },
  {
    "objectID": "changes-multivers.html#using-only-the-new-version",
    "href": "changes-multivers.html#using-only-the-new-version",
    "title": "31  Work with multiple dependency versions",
    "section": "\n31.4 Using only the new version",
    "text": "31.4 Using only the new version\nAt some point in the future, you’ll decide that the old version of the package is no longer widely used and you want to simplify your package by only depending on the new version. There are three steps:\n\nIn the DESCRIPTION, bump the required version of the dependency.\nSearch for dependency_has_new_interface(); remove the function definition and all uses (retaining the code used with the new version).\nRemove the additional build in .travis.yml."
  },
  {
    "objectID": "side-effects.html#what-is-a-side-effect",
    "href": "side-effects.html#what-is-a-side-effect",
    "title": "32  Side-effect soup",
    "section": "\n32.1 What is a side-effect?",
    "text": "32.1 What is a side-effect?\nThere are two main types of side-effect:\n\nthose that give feedback to the user.\nthose that change some global state.\n\n\n32.1.1 User feedback\n\nSignalling a condition, with message(), warning(), or stop().\nPrinting to the console with cat().\nDrawing to the current graphics device with base graphics or grid.\n\n32.1.2 Global state\n\nCreating (or modifying) an existing binding with &lt;-.\nModifying the search path by attaching a package with library().\nChanging the working directory with setwd().\nModifying a file on disk with (e.g.) write.csv().\nChanging a global option with options() or a base graphics parameter with gpar().\nSetting the random seed with set.seed()\nInstalling a package.\nChanging environment variables with Sys.setenv(), or indirectly via a function like Sys.setlocale().\nModifying a variable in an enclosing environment with assign() or &lt;&lt;-.\nModifying an object with reference semantics (like R6 or data.table).\n\nMore esoteric side-effects include:\n\nDetaching a package from the search path with detach().\nChanging the library path, where R looks for packages, with .libPaths()\nChanging the active graphics device with (e.g.) png() or dev.off().\nRegistering an S4 class, method, or generic with methods::setGeneric().\nModifying the internal .Random.seed"
  },
  {
    "objectID": "side-effects.html#what-are-some-examples",
    "href": "side-effects.html#what-are-some-examples",
    "title": "32  Side-effect soup",
    "section": "\n32.2 What are some examples?",
    "text": "32.2 What are some examples?\n\n\nThe summary of a linear model includes a p-value for the overall\nregression. This value is only computed when the summary is printed: you can see it but you can’t touch it.\n\nmod &lt;- lm(mpg ~ wt, data = mtcars)\nsummary(mod)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = mpg ~ wt, data = mtcars)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.5432 -2.3647 -0.1252  1.4096  6.8727 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\n#&gt; wt           -5.3445     0.5591  -9.559 1.29e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.046 on 30 degrees of freedom\n#&gt; Multiple R-squared:  0.7528, Adjusted R-squared:  0.7446 \n#&gt; F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10"
  },
  {
    "objectID": "side-effects.html#why-is-it-bad",
    "href": "side-effects.html#why-is-it-bad",
    "title": "32  Side-effect soup",
    "section": "\n32.3 Why is it bad?",
    "text": "32.3 Why is it bad?\nSide-effect soup is bad because:\n\nIf a function does some computation and has side-effects, it can be challenging to extract the results of computation.\n\nMakes code harder to analyse because it may have non-local effects. Take this code:\n\nx &lt;- 1\ny &lt;- compute(x)\nz &lt;- calculate(x, y)\n\ndf &lt;- data.frame(x = \"x\")\n\nIf compute() or calculate() don’t have side-effects then you can predict what df will be. But if compute() did options(stringsAsFactors = FALSE) then df would now contain a character vector rather than a factor.\n\n\nSide-effect soup increases the cognitive load of a function so should be used deliberately, and you should be especially cautious when combining them with other techniques that increase cognitive load like tidy-evaluation and type-instability."
  },
  {
    "objectID": "side-effects.html#how-avoid-it",
    "href": "side-effects.html#how-avoid-it",
    "title": "32  Side-effect soup",
    "section": "\n32.4 How avoid it?",
    "text": "32.4 How avoid it?\n\n32.4.1 Localise side-effects\nConstrain the side-effects to as small a scope as possible, and clean up automatically to avoid side-effects. withr\n\n32.4.2 Extract side-effects\nIt’s not side-effects that are bad, so much as mixing them with non-side-effect code.\nPut them in a function that is specifically focussed on the side-effect.\nIf your function is called primarily for its side-effects, it should return the primary data structure (which should be first argument), invisibly. This allows you to call it mid-pipe for its side-effects while allow the primary data to continue flowing through the pipe.\n\n32.4.3 Make side-effects noisy\nPrimary purpose of the entire package is side-effects: modifying files on disk to support package and project development. usethis functions are also designed to be noisy: as well as doing it’s job, each usethis function tells you what it’s doing.\nBut some usethis functions are building blocks for other more complex tasks.\n\n32.4.4 Provide an argument to suppress\nYou’ve probably used base::hist() for it’s side-effect of drawing a histogram:\n\nx &lt;- rnorm(1e5)\nhist(x)\n\n\n\n\nBut you might not know that hist() also returns the result of the computation. If you call plot = FALSE it will simply return the results of the computation:\n\nxhist &lt;- hist(x, plot = FALSE)\nstr(xhist)\n#&gt; List of 6\n#&gt;  $ breaks  : num [1:19] -4.5 -4 -3.5 -3 -2.5 -2 -1.5 -1 -0.5 0 ...\n#&gt;  $ counts  : int [1:18] 4 23 122 488 1597 4386 9238 14853 19031 19162 ...\n#&gt;  $ density : num [1:18] 0.00008 0.00046 0.00244 0.00976 0.03194 ...\n#&gt;  $ mids    : num [1:18] -4.25 -3.75 -3.25 -2.75 -2.25 -1.75 -1.25 -0.75 -0.25 0.25 ...\n#&gt;  $ xname   : chr \"x\"\n#&gt;  $ equidist: logi TRUE\n#&gt;  - attr(*, \"class\")= chr \"histogram\"\n\nThis is a good approach for retro-fitting older functions while making minimal API changes. However, I think it dilutes a function to be both used for plotting and for computing so should be best avoided in newer code.\n\n32.4.5 Use the print() method\nAn alternative approach would be to always return the computation, and instead perform the output in the print() method.\nOf course ggplot2 isn’t perfect: it creates an object that specifies the plot, but there’s no easy way to extract the underlying computation so if you’ve used geom_smooth() to add lines of best fit, there’s no way to extract the values. Again, you can see the results, but you can’t touch them, which is very frustrating!\n\n32.4.6 Make easy to undo\nIf all of the above techniques fail, you should at least make the side-effect easy to undo. A use technique to do this is to make sure that the function returns the previous values, and that it can take it’s own input.\nThis is how options() and par() work. You obviously can’t eliminate those functions because their complete purpose is have global changes! But they are designed in such away that you can easily undo their operation, making it possible to apply on a local basis.\nThere are two key ideas that make these functions easy to undo:\n\n\nThey invisibly return the previous values as a list:\n\noptions(my_option = 1)\nold &lt;- options(my_option = 2)\nstr(old)\n#&gt; List of 1\n#&gt;  $ my_option: num 1\n\n\n\nInstead of n named arguments, they can take a single named list:\n\nold &lt;- options(list(my_option1 = 1, my_option2 = 2))\n\n(I wouldn’t recommend copying this technique, but I’d instead recommend always taking a single named list. This makes the function because it has a single way to call it and makes it easy to extend the API in the future, as discussed in Chapter 17)\n\n\nTogether, this means that you easily can set options temporarily.:\n\ngetOption(\"my_option1\")\n#&gt; [1] 1\n\nold &lt;- options(my_option1 = 10)\ngetOption(\"my_option1\")\n#&gt; [1] 10\noptions(old)\n\ngetOption(\"my_option1\")\n#&gt; [1] 1\n\nIf temporarily setting options in a function, you should always restore the previous values using on.exit(): this ensures that the code is run regardless of how the function exits."
  },
  {
    "objectID": "side-effects.html#package-considerations",
    "href": "side-effects.html#package-considerations",
    "title": "32  Side-effect soup",
    "section": "\n32.5 Package considerations",
    "text": "32.5 Package considerations\nCode in package is executed at build-time.i.e. if you have:\n\nx &lt;- Sys.time()\n\nFor mac and windows, this will record when CRAN built the binary. For linux, when the package was installed.\nBeware copying functions from other packages:\n\nfoofy &lt;- barfy::foofy\n\nVersion of barfy might be different between run-time and build-time.\nIntroduces a build-time dependency.\nhttps://github.com/r-lib/devtools/issues/1788"
  },
  {
    "objectID": "spooky-action.html#whats-the-problem",
    "href": "spooky-action.html#whats-the-problem",
    "title": "33  Spooky action",
    "section": "\n33.1 What’s the problem?",
    "text": "33.1 What’s the problem?\nThere are no limits to what an function or script can do. After you call draw_plot() or source(\"analyse-data.R\"), you could discover that all the variables in your global environment have been deleted, or that 1000 new files have been created on your desktop. But these actions would be surprising, because generally you expect the impact of a function (or script) to be as limited as possible. Collectively, we call such side-effects “spooky actions” because the connection between action (calling a function or sourcing a script) and result (deleting objects or upgrading packages) is surprising. It’s like flipping a light-switch and discovering that the shower starts running, or having a poltergeist that rearranges the contents of your kitchen cupboards when you’re not looking.\nDeleting variables and creating files on your desktop are obviously surprising even if you’ve only just started using R. But there are other actions that are less obviously destructive, and only start to become surprising as your mental model of R matures. These include actions like:\n\nAttaching packages with library(). For example, ggplot2::geom_map() used to call library(maps) in order to make map data available to the function. This seems harmless, but if you were using purrr, it would break map() map() would now refer to maps::map() rather than purrr::map(). Because of functions in different packages can have the same name, attaching a package can change the behaviour of existing code.\nInstalling packages with install.packages(). If a script needs dplyr to work, and it’s not installed, it seems polite to install it on behalf of the user. But installing a new package can upgrade existing packages, which might break code in other projects. Install a package is a potentially destructive operation which should be done with care.\nDeleting objects in the global environment with rm(list = ls()). This might seem like a good way to reset the environment so that your script can run cleanly. But if someone else source()s your script, it will delete objects that might be important to them. (Of course, you’d hope that all of those objects could easily be recreated from another script, but that is not always the case).\n\nBecause R doesn’t constrain the potential scope of functions and scripts, you have to. By avoiding these actions, you will create code that is less surprising to other R users. At first, this might seem like tedious busywork. You might find that spooky action is convenient in the moment, and you might convince yourself that it’s necessary or a good idea. But as you share your code with more people and run more code that has been shared with you1, you’ll find spooky action to get more and more surprising and frustrating."
  },
  {
    "objectID": "spooky-action.html#what-precisely-is-a-spooky-action",
    "href": "spooky-action.html#what-precisely-is-a-spooky-action",
    "title": "33  Spooky action",
    "section": "\n33.2 What precisely is a spooky action?",
    "text": "33.2 What precisely is a spooky action?\nWe can make the notion of spooky action precise by thinking about trees. Code should only affect the tree beneath where it lives, so any action that reaches up, or across, the tree is a spooky action.\nThere are two important types of trees to consider:\n\n\nThe tree formed by files and directories. A script should only read from and write to directories beneath the directory where it lives. This explains why you shouldn’t install packages (because the package library usually lives elsewhere), and also explains why you shouldn’t create files on the desktop.\nThis rule can be relaxed in two small ways. Firstly, if the script lives in a project, it’s ok to read from and write to anywhere in the project (i.e. a file in R/ can read from data-raw/ and write to data/). Secondly, it’s always ok to write to the session specific temporary directory, tempdir(). This directory is automatically deleted when R closes, so does not have any lasting effects.\n\nThe tree of environments created by function calls. A function should only create and modify variables in its own environment or environments that it creates (typically by calling other functions). This explains why you shouldn’t attach packages (because that changes the search path), why you shouldn’t delete variables with rm(list = ls()), or assign to variables that you didn’t create with &lt;&lt;-."
  },
  {
    "objectID": "spooky-action.html#how-can-i-remediate-spooky-actions",
    "href": "spooky-action.html#how-can-i-remediate-spooky-actions",
    "title": "33  Spooky action",
    "section": "\n33.3 How can I remediate spooky actions?",
    "text": "33.3 How can I remediate spooky actions?\nIf you have read the above cautions, and still want to proceed, there are three ways you can make the spooky action as safe as possible:\n\nAllow the user to control the scope.\nMake the action less spooky by giving it a name that clearly describes what it will do.\nExplicitly check with the user before proceeding with the action.\nAdvertise what’s happening, so while the action might still be spooky, at least it isn’t surprising.\n\n\n33.3.1 Parameterise the action\nThe first technique is to allow the user to control where the action will occur. For example, instead of save_output_desktop(), you would write save_output(path), and require that the user provide the path.\n\n33.3.2 Advertise the action with a clear name\nIf you can’t parameterise the action, make it clear what’s going to happen from the outside. It is fine for function or scripts to have actions outside of their usual trees as long as it is implicit in the name:\n\nIt’s ok for &lt;- to modify the global environment, because that is its one job, and it’s obvious from the name (once you’ve learned about &lt;-, which happens very early). Similarly, it’s ok for save_output_to_desktop() to create files in on the desktop, or copy_to_clipboard() to copy text to the clipboard, because the action is clear from the name.\nIt’s fine for install.packages() to modify files outside of the current working directory because it’s designed specifically to install packages. Similarly, it’s ok for source(\"class-setup.R\") to install packages because the intent of a setup script is to get your computer into the same state as someone else’s.\n\nHere, it’s the name of the function or script that is really important. As soon as you\nNote that it’s the name that’s important - it’s fine for install.packages() to install packages, but it’s not ok as soon as it’s hidden behind even a very simple wrapper:\n\ncurrent_time &lt;- function() {\n  if (!requireNamespace(\"lubridate\", quietly = TRUE)) {\n    install.packages(\"lubridate\")\n  }\n  lubridate::now()\n}\ncurrent_time()\n#&gt; [1] \"2023-07-31 13:52:45 UTC\"\n\n\n33.3.3 Ask for confirmation\nIf you can’t parameterise the operation, and need to perform it from somewhere deep within the cope, make sure to confirm with the user before performing the action. The code below shows how you might do so when installing a package:\n\ninstall_if_needed &lt;- function(package) {\n  if (requireNamespace(package, quietly = TRUE)) {\n    return(invisible(TRUE))\n  }\n  \n  if (!interactive()) {\n    stop(package, \" is not installed\", call. = FALSE)\n  }\n  \n  title &lt;- paste0(package, \" is not installed. Do you wish to install now?\")\n  if (menu(c(\"Yes\", \"No\"), title = title) != 1) {\n    stop(\"Confirmation not received\", call. = FALSE)\n  }\n  \n  invisible(TRUE)\n}\n\nNote the use of interactive() here: if the user is not in an interactive setting (i.e. the code is being run with Rscript) and we can not get explicit confirmation, we shouldn’t make any changes. Also that all failures are errors: this ensures that the remainder of the function or script does not run if the user doesn’t confirm.\nIdeally this function would also clearly describe the consequences of your decision. For example, it would be nice to know if it will download a significant amount of data (since you might want to wait until your at a fast connection if downloading a 1 Gb data package), or if it will upgrade existing packages (since that might break other code).\nWriting code that checks with the user requires some care, and it’s easy to get the details wrong. That’s why it’s better to prefer one of the prior techniques.\n\n33.3.4 Advertise the side-effects\nIf you can’t get explicit confirmation from the user, at the very minimum you should clearly advertise what is happening. For example, when you call install.packages() it notifies you:\n\ninstall.packages(\"dplyr\")\n#&gt; Installing package into ‘/Users/hadley/R’\n#&gt; (as ‘lib’ is unspecified)\n#&gt; Trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.5/dplyr_0.8.0.1.tgz'\n#&gt; Content type 'application/x-gzip' length 6587031 bytes (6.3 MB)\n#&gt; ==================================================\n#&gt; downloaded 6.3 MB\n\nHowever, this message could do with some work:\n\nIt says installing “package”, without specifying which package (so if this is called inside another function it won’t be informative).\nIt doesn’t notify me which dependencies it’s also going to update.\nIt notifies me of the url it’s downloading from, which I don’t care about, and it only notifies me about the size when it’s finished downloading, by which time it too late to stop it.\n\nI would instead write something like this:\n\ninstall.packages(\"dplyr\")\n#&gt; Installing package dplyr to `/Users/hadley/R`\n#&gt; Also installing 3 dependencies: glue, rlang, R6\n\nWe’ll come back to the issue of informing the user in …"
  },
  {
    "objectID": "spooky-action.html#case-studies",
    "href": "spooky-action.html#case-studies",
    "title": "33  Spooky action",
    "section": "\n33.4 Case studies",
    "text": "33.4 Case studies\n\n33.4.1 save() and load()\n\nload() has a spooky action because it modifies variables in the current environment:\n\nx &lt;- 1\nload(\"spooky-action.rds\")\nx\n#&gt; [1] 10\n\nYou can make it less spooky by supplying verbose = TRUE. Here we learn that it also loaded a y object:\n\nload(\"spooky-action.rds\", verbose = TRUE)\n#&gt; Loading objects:\n#&gt;   x\n#&gt;   y\ny\n#&gt; [1] 100\n\n(In an ideal world verbose = TRUE would be default)\nBut generally, I’d avoid save() and load() altogether, and instead use saveRDS() and readRDS(), which read and write individual R objects to individual R files and work with &lt;-. This eliminates all spooky action:\n\nsaveRDS(x, \"x.rds\")\nx &lt;- readRDS(\"x.rds\")\n\n\nunlink(\"x.rds\")\n\n(readr provides readr::read_rds() and readr::write_rds() if the inconsistent naming conventions bother you like they bother me.)\n\n33.4.2 usethis\nThe usethis package is designed to support the process of developing a package of R code. It automates many of tedious setup steps by providing function like use_r() or use_test(). Many usethis functions modify the DESCRIPTION and create other files. usethis makes these actions as pedestrian as possible by:\n\nMaking it clear that the entire package is designed for the purpose of creating and modifying files, and the purpose of each function is clearly encoded in its named.\n\nFor any potential risky operation, e.g. overwriting an existing file, usethis explicitly asks for confirmation from the user. To make it harder to “click” through prompts without reading them, usethis uses random prompts in a random ordering.\n\nusethis::ui_yeah(\"Do you want to proceed?\")\n#&gt; Do you want to proceed?\n#&gt; \n#&gt; 1: Absolutely not\n#&gt; 2: Not now\n#&gt; 3: I agree\n\nusethis also works in concert with git to make sure that change are captured in a way that can easily be undone.\n\n\nWhen you call it, every usethis function describes what it is doing as it it doing it:\n\nusethis::create_package(\"mypackage\", open = FALSE)\n#&gt; ✔ Creating 'mypackage'\n#&gt; ✔ Setting active project to 'mypackage'\n#&gt; ✔ Creating 'R/'\n#&gt; ✔ Writing 'DESCRIPTION'\n#&gt; ✔ Writing 'NAMESPACE'\n#&gt; ✔ Writing 'mypackage.Rproj'\n#&gt; ✔ Adding '.Rproj.user' to '.gitignore'\n#&gt; ✔ Adding '^mypackage\\\\.Rproj$', '^\\\\.Rproj\\\\.user$' to '.Rbuildignore'\n\nThis is important, but it’s not clear how impactful it is because many functions produce enough output that reading through it all seems onerous and so generally most people don’t read it.\n\n\n33.4.3 &lt;&lt;-\n\nIf you haven’t heard of &lt;&lt;-, the super-assignment operator, before, feel free to skip this section as it’s an advanced technique that has relatively limited applications. They’re most important in the context of functionals, which you can read more about in Advanced R.\n&lt;&lt;- is safe if you use it to modify a variable in an environment that you control. For example, the following code creates a function that counts the number of times it is called. The use of &lt;&lt;- is safe because it only affects the environment created by make_counter(), not an external environment.\n\nmake_counter &lt;- function() {\n  i &lt;- 0\n  function() {\n    i &lt;&lt;- i + 1\n    i\n  }\n}\nc1 &lt;- make_counter()\nc2 &lt;- make_counter()\nc1()\n#&gt; [1] 1\nc1()\n#&gt; [1] 2\nc2()\n#&gt; [1] 1\n\nA more common use of &lt;&lt;- is to break one of the limitations of map()2 and use it like a for loop to iteratively modify input. For example, imagine you want to compute a cumulative sum. That’s straightforward to write with a for loop:\n\nx &lt;- rpois(10, 10)\n\nout &lt;- numeric(length(x))\nfor (i in seq_along(x)) {\n  if (i == 1) {\n    out[[i]] &lt;- x[[i]]\n  } else {\n    out[[i]] &lt;- x[[i]] + out[[i - 1]]\n  }\n}\n\nrbind(x, out)\n#&gt;     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#&gt; x      5   18    9    9    7    7    6   10    6    12\n#&gt; out    5   23   32   41   48   55   61   71   77    89\n\nA simple transformation from to use map() doesn’t work:\n\nlibrary(purrr)\nout &lt;- numeric(length(x))\nmap_dbl(seq_along(x), function(i) {\n  if (i == 1) {\n    out[[i]] &lt;- x[[i]]\n  } else {\n    out[[i]] &lt;- x[[i]] + out[[i - 1]]\n  }\n})\n#&gt;  [1]  5 18  9  9  7  7  6 10  6 12\n\nBecause the modification of out is happening inside of a function, R creates a copy of out (this is called copy-on-modify principle). Instead we need to use &lt;&lt;- to reach outside of the function to modify the outer out:\n\nmap_dbl(seq_along(x), function(i) {\n  if (i == 1) {\n    out[[i]] &lt;&lt;- x[[i]]\n  } else {\n    out[[i]] &lt;&lt;- x[[i]] + out[[i - 1]]\n  }\n})\n#&gt;  [1]  5 23 32 41 48 55 61 71 77 89\n\nThis use of &lt;&lt;- is a spooky action because we’re reaching up the tree of environments to modify an object created outside of the function. In this case, however, there’s no point in using map(): the point of those functions is to restrict what you can do compared to a for loop so that your code is easier to understand. R for data science has other examples of for loops that could be rewritten with map(), but shouldn’t be.\nNote that we could still wrap this code into a function to eliminate the spooky action:\n\ncumsum2 &lt;- function(x) {\n  out &lt;- numeric(length(x))\n  map_dbl(seq_along(x), function(i) {\n    if (i == 1) {\n      out[[i]] &lt;&lt;- x[[i]]\n    } else {\n      out[[i]] &lt;&lt;- x[[i]] + out[[i - 1]]\n    }\n  })\n  out\n}\n\nThis eliminates the spooky action because it’s now modifying an object that the function “owns”, but I still wouldn’t recommend it, as the use of map() and &lt;&lt;- only increases complexity for no gain compared to the use of a for loop.\n\n33.4.4 assign() in a for loop\nIt’s not uncommon for people to ask how to create multiple objects from for a loop. For example, maybe you have a vector of file names, and want to read each file into an individual object. With some effort you typically discover assign():\n\npaths &lt;- c(\"a.csv\", \"b.csv\", \"c.csv\")\nnames(paths) &lt;- c(\"a\", \"b\", \"c\")\n\nfor (i in seq_along(paths)) {\n  assign(names(paths)[[i]], read.csv(paths[[i]]))\n}\n\nThe main problem with this approach is that it does not facilitate composition. For example, imagine that you now wanted to figure out how many rows are in each of the data frames. Now you need to learn how to loop over a series of objects, where the name of the object is stored in a character vector. With some work, you might discover get() and write:\n\nlengths &lt;- numeric(length(names))\nfor (i in seq_along(paths)) {\n  lengths[[i]] &lt;- nrow(get(names(paths)[[i]]))\n}\n\nThis approach is not necessarily bad in and of itself3, but it tends to lead you down a high-friction path. Instead, if you learn a little about lists and functional programming techniques (e.g. with purrr), you’ll be able to write code like this:\n\nlibrary(purrr)\n\nfiles &lt;- map(paths, read.csv)\nlengths &lt;- map_int(files, nrow)\n\nThis obviously requires that you learn some new tools - but learning about map() and map_int() will pay off in many more situations than learning about assign() and get(). And because you can reuse map() and friends in many places, you’ll find that they get easier and easier to use over time.\nIt would certainly be possible to build tools in purrr to avoid having to learn about assign() and get() and to provide a polished interface for working with character vectors containing object names. But such functions would need to reach up the tree of environments, so would violate the “spooky action” principle, and thus I believe are best avoided."
  },
  {
    "objectID": "spooky-action.html#footnotes",
    "href": "spooky-action.html#footnotes",
    "title": "33  Spooky action",
    "section": "",
    "text": "Spooky actions tend to be particularly frustrating to those who teach R, because they have to run scripts from many students, and those scripts can end up doing wacky things to their computers.↩︎\npurrr::map() is basically interchangeable with base::lapply() so if you’re more familiar with lapply(), you can mentally substitute it for map() in all the code here.↩︎\nHowever, if you take this approach in multiple places in your code, you’ll need to make sure that you don’t use the same name in multiple loops because assign() will silently overwrite an existing variable. This might not happen commonly but because it’s silent, it will create a bug that is hard to detect.↩︎"
  },
  {
    "objectID": "err-call.html",
    "href": "err-call.html",
    "title": "34  Error call",
    "section": "",
    "text": "Don’t display the call when generating an error message. Either use stop(call. = FALSE) or rlang::abort() to avoid it.\nWhy not? Typically doesn’t display enough information to find the source of the call (since most errors are not from top-level function calls), and you can expect the most people to either use RStudio, or know how to call traceback()."
  },
  {
    "objectID": "err-constructor.html#whats-the-pattern",
    "href": "err-constructor.html#whats-the-pattern",
    "title": "35  Error constructors",
    "section": "\n35.1 What’s the pattern?",
    "text": "35.1 What’s the pattern?\nFollowing the rule of three, whenever you generate the same error in three or more places, you should extract it out into a common function, called an error constructor. This function should create a custom condition that contains components that can easily be tested and a conditionMessage() method that generates user friendly error messages.\n(This is a new pattern that we are currently rolling out across the tidyverse; it’s currently found in few packages.)\n\nlibrary(rlang)"
  },
  {
    "objectID": "err-constructor.html#why-is-this-important",
    "href": "err-constructor.html#why-is-this-important",
    "title": "35  Error constructors",
    "section": "\n35.2 Why is this important?",
    "text": "35.2 Why is this important?\n\nIf you don’t use an custom condition, you can only check that your function has generated the correct error by matching the text of the error message with a regular expression. This is fragile because the text of error messages changes relatively frequently, causing spurious test failures.\nYou can use custom conditions for one-off errors, but generally the extra implementation work is not worth the pay off. That’s why we recommend only using an error constructor for repeated errors.\nIt gives more precise control over error handling with tryCatch(). This is particularly useful in packages because you may be able to give more useful high-level error mesasges by wrapping a specific low-level error.\nAs you start using this technique for more error messages you can create a hierarchy of errors that allows you to borrow behaviour, reducing the amount of code you need to write.\nOnce you have identified all the errors that can be thrown by a function, you can add a @section Throws: to the documentation that precisely describes the possible failure modes."
  },
  {
    "objectID": "err-constructor.html#what-does-an-error-constructor-do",
    "href": "err-constructor.html#what-does-an-error-constructor-do",
    "title": "35  Error constructors",
    "section": "\n35.3 What does an error constructor do?",
    "text": "35.3 What does an error constructor do?\nAn error constructor is very similar to an S3 constructor, as its job is to extract out repeated code and generate a rich object that can easily be computed with. The primary difference is that instead of creating and returning a new object, it creates a custom error and immediately throws it with abort().\nHere’s a simple imaginary error that might be thrown by fs if it couldn’t find a file:\n\nstop_not_found &lt;- function(path) {\n  abort(\n    .subclass = \"fs_error_not_found\",\n    path = path\n  )\n}\n\nNote the naming scheme:\n\nThe function should be called stop_{error_type}\nThe error class should be {package}_error_{error_type}.\n\nThe function should have one argument for each varying part of the error, and these argument should be passed onto abort() to be stored in the condition object.\nTo generate the error message shown to the user, provide a conditionMessage() method:\n\n#' @export\nconditionMessage.fs_error_not_found &lt;- function(c) {\n  glue::glue_data(c, \"'{path}' not found\")\n}\n\n\nstop_not_found(\"a.csv\")\n#&gt; Error: 'a.csv' not found\n\nThis method must be exported, because you are defining a method for a generic in another package, and it will often use glue::glue_data() to assemble the components of the condition into a string. See https://style.tidyverse.org/error-messages.html for advice on writing the error message."
  },
  {
    "objectID": "err-constructor.html#how-do-i-test",
    "href": "err-constructor.html#how-do-i-test",
    "title": "35  Error constructors",
    "section": "\n35.4 How do I test?",
    "text": "35.4 How do I test?\n\nlibrary(testthat)\n#&gt; \n#&gt; Attaching package: 'testthat'\n#&gt; The following objects are masked from 'package:rlang':\n#&gt; \n#&gt;     is_false, is_null, is_true\n\n\n35.4.1 Test the constructor\nFirstly, you should test the error constructor. The primary goal of this test is to ensure that the error constructor generates a message that is useful to humans, which you can not automate. This means that you can not use a unit test (because the desired output is not known) and instead you need to use a regression test, so you can ensure that the message does not change unexpectedly. For that reason the best approach is usually to use verify_output(), e.g.:\n\ntest_that(\"stop_not_found() generates useful error message\", {\n  verify_output(test_path(\"test-stop-not-found.txt\"), {\n    stop_not_found(\"a.csv\")\n  })\n})\n\nThis is useful for pull requests because verify_output() generates a complete error messages in a text file that can easily be read and reviewed.\nIf your error has multiple arguments, or your conditionMessage() method contains if statements, you should generally attempt to cover them all in a test case.\n\n35.4.2 Test usage\nNow that you have an error constructor, you’ll need to slightly change how you test your functions that use the error constructor. For example, take this imaginary example for reading a file into a single string:\n\nread_lines &lt;- function(x) {\n  if (!file.exists(x)) {\n    stop_not_found(x)\n  }\n  paste0(readLines(x), collapse = \"\\n\")\n}\n\nPreviously, you might have written:\n\nexpect_error(read_lines(\"missing-file.txt\"), \"not found\")\n\nBut, now as you see, testthat gives you a warning that suggests you need to use the class argument instead:\n\nexpect_error(read_lines(\"missing-file.txt\"), class = \"fs_error_not_found\")\n\nThis is less fragile because you can now change the error message without having to worry about breaking existing tests.\nIf you also want to check components of the error object, note that expect_error() returns it:\n\ncnd &lt;- expect_error(read_lines(\"missing-file.txt\"), class = \"fs_error_not_found\")\nexpect_equal(cnd$path, \"missing-file.txt\")\n\nI don’t think this level of testing is generally important, so you should only use it because the error generation code is complex conditions, or you have identified a bug."
  },
  {
    "objectID": "err-constructor.html#error-hierarchies",
    "href": "err-constructor.html#error-hierarchies",
    "title": "35  Error constructors",
    "section": "\n35.5 Error hierarchies",
    "text": "35.5 Error hierarchies\nAs you start writing more and more error constructors, you may notice that you are starting to share code between them because the errors form a natural hierarchy. To take advantage of this hierarchy to reduce the amount of code you need to write, you can make the errors subclassable by adding ... and class arguments:\n\nstop_not_found &lt;- function(path, ..., class = character()) {\n  abort(\n    .subclass = c(class, \"fs_error_not_found\"),\n    path = path\n  )\n}\n\nThen the subclasses can call this constructor, and the problem becomes one of S3 class design. We currently have little experience with this, so use with caution."
  }
]